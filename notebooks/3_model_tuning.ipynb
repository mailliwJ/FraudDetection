{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 7ms/step - loss: 0.0081 - precision_at_recall_4: 0.0124 - val_loss: 9.5676e-04 - val_precision_at_recall_4: 0.8676\n",
      "Epoch 2/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - loss: 0.0011 - precision_at_recall_4: 0.6987 - val_loss: 9.2607e-04 - val_precision_at_recall_4: 0.8714\n",
      "Epoch 3/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 5ms/step - loss: 9.0652e-04 - precision_at_recall_4: 0.8240 - val_loss: 8.3359e-04 - val_precision_at_recall_4: 0.8696\n",
      "Epoch 4/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 5ms/step - loss: 8.6359e-04 - precision_at_recall_4: 0.7087 - val_loss: 0.0010 - val_precision_at_recall_4: 0.8732\n",
      "Epoch 5/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 8.5304e-04 - precision_at_recall_4: 0.8569 - val_loss: 7.6726e-04 - val_precision_at_recall_4: 0.9032\n",
      "Epoch 6/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - loss: 5.2332e-04 - precision_at_recall_4: 0.8634 - val_loss: 9.1133e-04 - val_precision_at_recall_4: 0.8451\n",
      "Epoch 7/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - loss: 5.9895e-04 - precision_at_recall_4: 0.8929 - val_loss: 0.0011 - val_precision_at_recall_4: 0.8571\n",
      "Epoch 8/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 5ms/step - loss: 6.5185e-04 - precision_at_recall_4: 0.8022 - val_loss: 9.5137e-04 - val_precision_at_recall_4: 0.8889\n",
      "Epoch 9/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - loss: 4.6227e-04 - precision_at_recall_4: 0.9112 - val_loss: 9.6954e-04 - val_precision_at_recall_4: 0.8696\n",
      "Epoch 10/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - loss: 6.1353e-04 - precision_at_recall_4: 0.8778 - val_loss: 9.3859e-04 - val_precision_at_recall_4: 0.9032\n",
      "Epoch 11/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 5ms/step - loss: 5.1996e-04 - precision_at_recall_4: 0.8846 - val_loss: 0.0011 - val_precision_at_recall_4: 0.8676\n",
      "Epoch 12/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - loss: 3.7273e-04 - precision_at_recall_4: 0.9022 - val_loss: 0.0011 - val_precision_at_recall_4: 0.8592\n",
      "Epoch 13/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 5ms/step - loss: 3.6810e-04 - precision_at_recall_4: 0.8993 - val_loss: 0.0011 - val_precision_at_recall_4: 0.8889\n",
      "Epoch 14/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5ms/step - loss: 2.3150e-04 - precision_at_recall_4: 0.9284 - val_loss: 0.0011 - val_precision_at_recall_4: 0.9500\n",
      "Epoch 15/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 5ms/step - loss: 4.8482e-04 - precision_at_recall_4: 0.9102 - val_loss: 0.0015 - val_precision_at_recall_4: 0.8750\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-13 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-13 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-13 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-13 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-13 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-13 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-13 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-13 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-13 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-13 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(force_int_remainder_cols=False,\n",
       "                                   remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;drop_cols&#x27;, &#x27;drop&#x27;,\n",
       "                                                  [&#x27;Time&#x27;, &#x27;Amount&#x27;])])),\n",
       "                (&#x27;mlp&#x27;,\n",
       "                 KerasClassifier(batch_size=32, callbacks=[&lt;keras.src.callbacks.early_stopping.EarlyStopping object at 0x151dc6c00&gt;], epochs=100, model=&lt;function create_model at 0x1538285e0&gt;, validation_split=0.2))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-86\" type=\"checkbox\" ><label for=\"sk-estimator-id-86\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(force_int_remainder_cols=False,\n",
       "                                   remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;drop_cols&#x27;, &#x27;drop&#x27;,\n",
       "                                                  [&#x27;Time&#x27;, &#x27;Amount&#x27;])])),\n",
       "                (&#x27;mlp&#x27;,\n",
       "                 KerasClassifier(batch_size=32, callbacks=[&lt;keras.src.callbacks.early_stopping.EarlyStopping object at 0x151dc6c00&gt;], epochs=100, model=&lt;function create_model at 0x1538285e0&gt;, validation_split=0.2))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-87\" type=\"checkbox\" ><label for=\"sk-estimator-id-87\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;preprocessor: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(force_int_remainder_cols=False, remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;drop_cols&#x27;, &#x27;drop&#x27;, [&#x27;Time&#x27;, &#x27;Amount&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-88\" type=\"checkbox\" ><label for=\"sk-estimator-id-88\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">drop_cols</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;Time&#x27;, &#x27;Amount&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-89\" type=\"checkbox\" ><label for=\"sk-estimator-id-89\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">drop</label><div class=\"sk-toggleable__content fitted\"><pre>drop</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-90\" type=\"checkbox\" ><label for=\"sk-estimator-id-90\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">remainder</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;V1&#x27;, &#x27;V2&#x27;, &#x27;V3&#x27;, &#x27;V4&#x27;, &#x27;V5&#x27;, &#x27;V6&#x27;, &#x27;V7&#x27;, &#x27;V8&#x27;, &#x27;V9&#x27;, &#x27;V10&#x27;, &#x27;V11&#x27;, &#x27;V12&#x27;, &#x27;V13&#x27;, &#x27;V14&#x27;, &#x27;V15&#x27;, &#x27;V16&#x27;, &#x27;V17&#x27;, &#x27;V18&#x27;, &#x27;V19&#x27;, &#x27;V20&#x27;, &#x27;V21&#x27;, &#x27;V22&#x27;, &#x27;V23&#x27;, &#x27;V24&#x27;, &#x27;V25&#x27;, &#x27;V26&#x27;, &#x27;V27&#x27;, &#x27;V28&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-91\" type=\"checkbox\" ><label for=\"sk-estimator-id-91\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">passthrough</label><div class=\"sk-toggleable__content fitted\"><pre>passthrough</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-92\" type=\"checkbox\" ><label for=\"sk-estimator-id-92\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">KerasClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;function create_model at 0x1538285e0&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=32\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=[&lt;keras.src.callbacks.early_stopping.EarlyStopping object at 0x151dc6c00&gt;]\n",
       "\tvalidation_split=0.2\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=100\n",
       "\tclass_weight=None\n",
       ")</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(force_int_remainder_cols=False,\n",
       "                                   remainder='passthrough',\n",
       "                                   transformers=[('drop_cols', 'drop',\n",
       "                                                  ['Time', 'Amount'])])),\n",
       "                ('mlp',\n",
       "                 KerasClassifier(batch_size=32, callbacks=[<keras.src.callbacks.early_stopping.EarlyStopping object at 0x151dc6c00>], epochs=100, model=<function create_model at 0x1538285e0>, validation_split=0.2))])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define Early Stopping object\n",
    "es = EarlyStopping(\n",
    "    monitor='val_loss', patience=10, restore_best_weights=True, verbose=1\n",
    ")\n",
    "\n",
    "# Make mlp classifier object\n",
    "mlp_clf = KerasClassifier(model=create_model,\n",
    "                          epochs=100,\n",
    "                          batch_size=32,\n",
    "                          validation_split=0.2,\n",
    "                          callbacks=[es])\n",
    "\n",
    "# Define pipeline with MLP classifier\n",
    "mlp_pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_v1),\n",
    "    ('mlp', mlp_clf)\n",
    "])\n",
    "\n",
    "# Fit pipeline\n",
    "mlp_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2660/2660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict on test set and visualize performance with confusion matrix\n",
    "y_pred_mlp = mlp_pipe.predict(X_test)\n",
    "\n",
    "cm_mlp = confusion_matrix(y_test, y_pred_mlp)\n",
    "\n",
    "mlp_results = {\n",
    "    'Model': 'Multi Layer Perceptron',\n",
    "    'Sampling': 'NONE',\n",
    "    'Recall':round(recall_score(y_test, y_pred_mlp),2),\n",
    "    'Precision': round(precision_score(y_test, y_pred_mlp),2),\n",
    "    'F1 Score': round(f1_score(y_test, y_pred_mlp),2),\n",
    "    'PR-AUC': round(average_precision_score(y_test, y_pred_mlp),2),\n",
    "    'ROC-AUC': round(roc_auc_score(y_test, y_pred_mlp),2),\n",
    "    'True Negative': cm_mlp[0,0],\n",
    "    'False Positive': cm_mlp[0,1],\n",
    "    'False Negative': cm_mlp[1,0],\n",
    "    'True Positive': cm_mlp[1,1]\n",
    "}\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_mlp, display_labels=['Not Fraud', 'Fraud'], values_format='d', cmap='Purples');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_results_df = pd.DataFrame([mlp_results]).set_index(['Model','Sampling'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>PR-AUC</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>True Negative</th>\n",
       "      <th>False Positive</th>\n",
       "      <th>False Negative</th>\n",
       "      <th>True Positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>Sampling</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Multi Layer Perceptron</th>\n",
       "      <th>NONE</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.88</td>\n",
       "      <td>84963</td>\n",
       "      <td>13</td>\n",
       "      <td>35</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Recall  Precision  F1 Score  PR-AUC  ROC-AUC  \\\n",
       "Model                  Sampling                                                 \n",
       "Multi Layer Perceptron NONE        0.75       0.89      0.82    0.67     0.88   \n",
       "\n",
       "                                 True Negative  False Positive  \\\n",
       "Model                  Sampling                                  \n",
       "Multi Layer Perceptron NONE              84963              13   \n",
       "\n",
       "                                 False Negative  True Positive  \n",
       "Model                  Sampling                                 \n",
       "Multi Layer Perceptron NONE                  35            107  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores_df = pd.read_csv('../data/test_scores.csv')\n",
    "test_scores_df = test_scores_df.set_index(['Model','Sampling'])\n",
    "test_scores_df = pd.concat([test_scores_df, mlp_results_df])\n",
    "test_scores_df.to_csv('../data/test_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>PR-AUC</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>True Negative</th>\n",
       "      <th>False Positive</th>\n",
       "      <th>False Negative</th>\n",
       "      <th>True Positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>Sampling</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Logistic Regression</th>\n",
       "      <th>No Sampling</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.81</td>\n",
       "      <td>84966</td>\n",
       "      <td>10</td>\n",
       "      <td>54</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RUS</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.93</td>\n",
       "      <td>83990</td>\n",
       "      <td>986</td>\n",
       "      <td>17</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTE</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.92</td>\n",
       "      <td>84436</td>\n",
       "      <td>540</td>\n",
       "      <td>22</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTE+RUS</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.92</td>\n",
       "      <td>84442</td>\n",
       "      <td>534</td>\n",
       "      <td>22</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTETomek</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.91</td>\n",
       "      <td>84601</td>\n",
       "      <td>375</td>\n",
       "      <td>25</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTEENN</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.91</td>\n",
       "      <td>84597</td>\n",
       "      <td>379</td>\n",
       "      <td>25</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Random Forest</th>\n",
       "      <th>No Sampling</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.88</td>\n",
       "      <td>84970</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RUS</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.92</td>\n",
       "      <td>84036</td>\n",
       "      <td>940</td>\n",
       "      <td>22</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTE</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.89</td>\n",
       "      <td>84960</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTE+RUS</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.90</td>\n",
       "      <td>84956</td>\n",
       "      <td>20</td>\n",
       "      <td>29</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTETomek</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.88</td>\n",
       "      <td>84958</td>\n",
       "      <td>18</td>\n",
       "      <td>33</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTEENN</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.89</td>\n",
       "      <td>84953</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">XGBoost</th>\n",
       "      <th>No Sampling</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.89</td>\n",
       "      <td>84967</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RUS</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.92</td>\n",
       "      <td>84037</td>\n",
       "      <td>939</td>\n",
       "      <td>21</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTE</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.90</td>\n",
       "      <td>84951</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTE+RUS</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.90</td>\n",
       "      <td>84940</td>\n",
       "      <td>36</td>\n",
       "      <td>29</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTETomek</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.90</td>\n",
       "      <td>84952</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTEENN</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.90</td>\n",
       "      <td>84940</td>\n",
       "      <td>36</td>\n",
       "      <td>29</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Multi Layer Perceptron</th>\n",
       "      <th>NONE</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.87</td>\n",
       "      <td>84955</td>\n",
       "      <td>21</td>\n",
       "      <td>36</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NONE</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.88</td>\n",
       "      <td>84963</td>\n",
       "      <td>13</td>\n",
       "      <td>35</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Recall  Precision  F1 Score  PR-AUC  \\\n",
       "Model                  Sampling                                           \n",
       "Logistic Regression    No Sampling    0.62       0.90      0.73    0.56   \n",
       "                       RUS            0.88       0.11      0.20    0.10   \n",
       "                       SMOTE          0.85       0.18      0.30    0.15   \n",
       "                       SMOTE+RUS      0.85       0.18      0.30    0.16   \n",
       "                       SMOTETomek     0.82       0.24      0.37    0.20   \n",
       "                       SMOTEENN       0.82       0.24      0.37    0.19   \n",
       "Random Forest          No Sampling    0.76       0.95      0.84    0.72   \n",
       "                       RUS            0.85       0.11      0.20    0.10   \n",
       "                       SMOTE          0.79       0.88      0.83    0.69   \n",
       "                       SMOTE+RUS      0.80       0.85      0.82    0.68   \n",
       "                       SMOTETomek     0.77       0.86      0.81    0.66   \n",
       "                       SMOTEENN       0.78       0.83      0.80    0.65   \n",
       "XGBoost                No Sampling    0.77       0.92      0.84    0.72   \n",
       "                       RUS            0.85       0.11      0.20    0.10   \n",
       "                       SMOTE          0.80       0.82      0.81    0.65   \n",
       "                       SMOTE+RUS      0.80       0.76      0.78    0.60   \n",
       "                       SMOTETomek     0.80       0.83      0.81    0.66   \n",
       "                       SMOTEENN       0.80       0.76      0.78    0.60   \n",
       "Multi Layer Perceptron NONE           0.75       0.83      0.79    0.62   \n",
       "                       NONE           0.75       0.89      0.82    0.67   \n",
       "\n",
       "                                    ROC-AUC  True Negative  False Positive  \\\n",
       "Model                  Sampling                                              \n",
       "Logistic Regression    No Sampling     0.81          84966              10   \n",
       "                       RUS             0.93          83990             986   \n",
       "                       SMOTE           0.92          84436             540   \n",
       "                       SMOTE+RUS       0.92          84442             534   \n",
       "                       SMOTETomek      0.91          84601             375   \n",
       "                       SMOTEENN        0.91          84597             379   \n",
       "Random Forest          No Sampling     0.88          84970               6   \n",
       "                       RUS             0.92          84036             940   \n",
       "                       SMOTE           0.89          84960              16   \n",
       "                       SMOTE+RUS       0.90          84956              20   \n",
       "                       SMOTETomek      0.88          84958              18   \n",
       "                       SMOTEENN        0.89          84953              23   \n",
       "XGBoost                No Sampling     0.89          84967               9   \n",
       "                       RUS             0.92          84037             939   \n",
       "                       SMOTE           0.90          84951              25   \n",
       "                       SMOTE+RUS       0.90          84940              36   \n",
       "                       SMOTETomek      0.90          84952              24   \n",
       "                       SMOTEENN        0.90          84940              36   \n",
       "Multi Layer Perceptron NONE            0.87          84955              21   \n",
       "                       NONE            0.88          84963              13   \n",
       "\n",
       "                                    False Negative  True Positive  \n",
       "Model                  Sampling                                    \n",
       "Logistic Regression    No Sampling              54             88  \n",
       "                       RUS                      17            125  \n",
       "                       SMOTE                    22            120  \n",
       "                       SMOTE+RUS                22            120  \n",
       "                       SMOTETomek               25            117  \n",
       "                       SMOTEENN                 25            117  \n",
       "Random Forest          No Sampling              34            108  \n",
       "                       RUS                      22            120  \n",
       "                       SMOTE                    30            112  \n",
       "                       SMOTE+RUS                29            113  \n",
       "                       SMOTETomek               33            109  \n",
       "                       SMOTEENN                 31            111  \n",
       "XGBoost                No Sampling              32            110  \n",
       "                       RUS                      21            121  \n",
       "                       SMOTE                    29            113  \n",
       "                       SMOTE+RUS                29            113  \n",
       "                       SMOTETomek               28            114  \n",
       "                       SMOTEENN                 29            113  \n",
       "Multi Layer Perceptron NONE                     36            106  \n",
       "                       NONE                     35            107  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'binary_focal_crossentropy'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp_pipe.named_steps['mlp'].model_.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 20:18:10.513174: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-10 20:18:10.532538: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-10 20:18:10.547021: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-10 20:18:10.547350: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5ms/step - loss: 0.0066 - precision_at_recall_3: 0.0063 - val_loss: 0.0014 - val_precision_at_recall_3: 0.8846\n",
      "Epoch 2/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5ms/step - loss: 0.0062 - precision_at_recall_3: 0.0063 - val_loss: 0.0025 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 2/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5ms/step - loss: 0.0058 - precision_at_recall_3: 0.0250 - val_loss: 9.4150e-04 - val_precision_at_recall_3: 0.9038\n",
      "Epoch 2/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5ms/step - loss: 0.0081 - precision_at_recall_3: 0.0073 - val_loss: 8.0145e-04 - val_precision_at_recall_3: 0.8889\n",
      "\u001b[1m   1/3973\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:18\u001b[0m 95ms/step - loss: 8.8625e-05 - precision_at_recall_3: 0.0000e+00Epoch 2/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0014 - precision_at_recall_3: 0.5725 - val_loss: 7.5840e-04 - val_precision_at_recall_3: 0.8596\n",
      "Epoch 3/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0016 - precision_at_recall_3: 0.4446 - val_loss: 9.8506e-04 - val_precision_at_recall_3: 0.8654\n",
      "Epoch 3/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0014 - precision_at_recall_3: 0.5667 - val_loss: 6.8340e-04 - val_precision_at_recall_3: 0.9038\n",
      "Epoch 3/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0010 - precision_at_recall_3: 0.5696 - val_loss: 9.2892e-04 - val_precision_at_recall_3: 0.8800\n",
      "Epoch 3/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0010 - precision_at_recall_3: 0.7343 - val_loss: 8.5913e-04 - val_precision_at_recall_3: 0.8679\n",
      "Epoch 4/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 9.9769e-04 - precision_at_recall_3: 0.7578 - val_loss: 9.1825e-04 - val_precision_at_recall_3: 0.8596\n",
      "Epoch 4/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0011 - precision_at_recall_3: 0.6289 - val_loss: 0.0011 - val_precision_at_recall_3: 0.9038\n",
      "Epoch 4/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 6ms/step - loss: 0.0011 - precision_at_recall_3: 0.6144 - val_loss: 6.3261e-04 - val_precision_at_recall_3: 0.9038\n",
      "Epoch 4/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 9.9148e-04 - precision_at_recall_3: 0.5602 - val_loss: 8.3421e-04 - val_precision_at_recall_3: 0.8750\n",
      "Epoch 5/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 9.1459e-04 - precision_at_recall_3: 0.8008 - val_loss: 9.8092e-04 - val_precision_at_recall_3: 0.9000\n",
      "Epoch 5/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.0012 - precision_at_recall_3: 0.3884 - val_loss: 6.5823e-04 - val_precision_at_recall_3: 0.9074\n",
      "Epoch 5/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 9.2288e-04 - precision_at_recall_3: 0.8380 - val_loss: 9.9221e-04 - val_precision_at_recall_3: 0.8596\n",
      "Epoch 5/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 7.3549e-04 - precision_at_recall_3: 0.8238 - val_loss: 8.5581e-04 - val_precision_at_recall_3: 0.9020\n",
      "Epoch 6/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 9.1623e-04 - precision_at_recall_3: 0.7986 - val_loss: 6.0198e-04 - val_precision_at_recall_3: 0.9074\n",
      "\u001b[1m 615/3973\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 5.3039e-04 - precision_at_recall_3: 0.8205Epoch 6/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 8.4881e-04 - precision_at_recall_3: 0.7636 - val_loss: 0.0011 - val_precision_at_recall_3: 0.9375\n",
      "\u001b[1m 750/3973\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 5.4228e-04 - precision_at_recall_3: 0.8294Epoch 6/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 7.8036e-04 - precision_at_recall_3: 0.8186 - val_loss: 0.0010 - val_precision_at_recall_3: 0.9000\n",
      "Epoch 7/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 9.0102e-04 - precision_at_recall_3: 0.6376 - val_loss: 5.6379e-04 - val_precision_at_recall_3: 0.9074\n",
      "\u001b[1m 523/3973\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 0.0012 - precision_at_recall_3: 0.7599Epoch 7/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step - loss: 9.3246e-04 - precision_at_recall_3: 0.8562 - val_loss: 7.7228e-04 - val_precision_at_recall_3: 0.8596\n",
      "Epoch 6/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 9.0323e-04 - precision_at_recall_3: 0.7462 - val_loss: 8.7409e-04 - val_precision_at_recall_3: 0.8654\n",
      "Epoch 7/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 6.7820e-04 - precision_at_recall_3: 0.8661 - val_loss: 6.1073e-04 - val_precision_at_recall_3: 0.9783\n",
      "Epoch 8/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 9.6590e-04 - precision_at_recall_3: 0.7358 - val_loss: 0.0010 - val_precision_at_recall_3: 0.9362\n",
      "Epoch 8/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 7.2953e-04 - precision_at_recall_3: 0.8692 - val_loss: 7.6895e-04 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 7/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 8.4893e-04 - precision_at_recall_3: 0.8371 - val_loss: 9.9352e-04 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 8/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 7.0938e-04 - precision_at_recall_3: 0.8315 - val_loss: 8.1248e-04 - val_precision_at_recall_3: 0.8545\n",
      "Epoch 8/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 8.9012e-04 - precision_at_recall_3: 0.7652 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8596\n",
      "Epoch 9/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 6.4165e-04 - precision_at_recall_3: 0.7852 - val_loss: 8.0742e-04 - val_precision_at_recall_3: 0.8772\n",
      "\u001b[1m1842/3973\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - loss: 7.9979e-04 - precision_at_recall_3: 0.5112Epoch 9/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - loss: 7.6157e-04 - precision_at_recall_3: 0.8308 - val_loss: 0.0010 - val_precision_at_recall_3: 0.8727\n",
      "Epoch 10/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step - loss: 8.6151e-04 - precision_at_recall_3: 0.6395 - val_loss: 6.0525e-04 - val_precision_at_recall_3: 0.9184\n",
      "Epoch 9/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 6ms/step - loss: 7.6959e-04 - precision_at_recall_3: 0.8570 - val_loss: 9.9518e-04 - val_precision_at_recall_3: 0.9200\n",
      "Epoch 9/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 6.9422e-04 - precision_at_recall_3: 0.8629 - val_loss: 7.4873e-04 - val_precision_at_recall_3: 0.8727\n",
      "Epoch 10/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - loss: 7.4911e-04 - precision_at_recall_3: 0.7798 - val_loss: 9.8669e-04 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 7.9551e-04 - precision_at_recall_3: 0.788\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 7.3298e-04 - precision_at_recall_3: 0.7641 - val_loss: 7.2205e-04 - val_precision_at_recall_3: 0.9038\n",
      "Epoch 10/100\n",
      "\u001b[1m3764/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.8087e-04 - precision_at_recall_3: 0.8021Epoch 1/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 7.7987e-04 - precision_at_recall_3: 0.8030 - val_loss: 8.8859e-04 - val_precision_at_recall_3: 0.9038\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.0070 - precision_at_recall_3: 0.000.786\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 4ms/step - loss: 8.0631e-04 - precision_at_recall_3: 0.8627 - val_loss: 0.0010 - val_precision_at_recall_3: 0.9020\n",
      "Epoch 10/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - loss: 8.3980e-04 - precision_at_recall_3: 0.7898 - val_loss: 6.8780e-04 - val_precision_at_recall_3: 0.9388\n",
      "Epoch 11/100\n",
      "\u001b[1m 966/3973\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 6.1195e-04 - precision_at_recall_3: 0.8112Epoch 1/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5ms/step - loss: 0.0055 - precision_at_recall_3: 0.0060 - val_loss: 0.0010 - val_precision_at_recall_3: 0.8704\n",
      "\u001b[1m1225/3973\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 7.2295e-04 - precision_at_recall_3: 0.5779Epoch 2/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 7.4106e-04 - precision_at_recall_3: 0.8058 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8679\n",
      "\u001b[1m2374/3973\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.0089 - precision_at_recall_3: 0.0042Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 7.3610e-04 - precision_at_recall_3: 0.6906 - val_loss: 6.0527e-04 - val_precision_at_recall_3: 0.9184\n",
      "Epoch 12/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/stepp - loss: 4.5554e-04 - precision_at_recall_3: 0.88\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0013 - precision_at_recall_3: 0.3380 - val_loss: 9.3869e-04 - val_precision_at_recall_3: 0.8654\n",
      "\u001b[1m1985/3973\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 5.4981e-04 - precision_at_recall_3: 0.8102Epoch 3/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0071 - precision_at_recall_3: 0.0055 - val_loss: 8.9985e-04 - val_precision_at_recall_3: 0.8824\n",
      "\u001b[1m 483/3973\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 0.0013 - precision_at_recall_3: 0.8726Epoch 2/50\n",
      "\u001b[1m2624/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5.8725e-04 - precision_at_recall_3: 0.8168Epoch 1/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 6.3035e-04 - precision_at_recall_3: 0.8200 - val_loss: 5.6608e-04 - val_precision_at_recall_3: 0.9783\n",
      "Epoch 13/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0013 - precision_at_recall_3: 0.7034 - val_loss: 9.2295e-04 - val_precision_at_recall_3: 0.8704\n",
      "\u001b[1m2242/3973\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0088 - precision_at_recall_3: 0.0019Epoch 4/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0028 - precision_at_recall_3: 0.0683 - val_loss: 0.0013 - val_precision_at_recall_3: 0.9057\n",
      "\u001b[1m2220/3973\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 6.7696e-04 - precision_at_recall_3: 0.7951Epoch 3/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0066 - precision_at_recall_3: 0.0061 - val_loss: 0.0014 - val_precision_at_recall_3: 0.8448\n",
      "Epoch 2/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 6.6511e-04 - precision_at_recall_3: 0.8198 - val_loss: 6.1081e-04 - val_precision_at_recall_3: 0.9583\n",
      "Epoch 14/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 8.4179e-04 - precision_at_recall_3: 0.6936 - val_loss: 0.0010 - val_precision_at_recall_3: 0.8654\n",
      "Epoch 5/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0023 - precision_at_recall_3: 0.0985 - val_loss: 8.5652e-04 - val_precision_at_recall_3: 0.8909\n",
      "\u001b[1m2793/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0018 - precision_at_recall_3: 0.3430Epoch 4/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0018 - precision_at_recall_3: 0.2890 - val_loss: 0.0014 - val_precision_at_recall_3: 0.8679\n",
      "Epoch 3/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - loss: 9.2765e-04 - precision_at_recall_3: 0.6944 - val_loss: 8.5696e-04 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 6/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - loss: 0.0031 - precision_at_recall_3: 0.1236 - val_loss: 0.0019 - val_precision_at_recall_3: 0.8333\n",
      "Epoch 5/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.0027 - precision_at_recall_3: 0.0629 - val_loss: 0.0016 - val_precision_at_recall_3: 0.8421\n",
      "\u001b[1m2606/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 6.6259e-04 - precision_at_recall_3: 0.7047Epoch 4/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5ms/step - loss: 6.9124e-04 - precision_at_recall_3: 0.8408 - val_loss: 6.7024e-04 - val_precision_at_recall_3: 1.0000\n",
      "Epoch 15/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 7.4395e-04 - precision_at_recall_3: 0.6920 - val_loss: 9.8830e-04 - val_precision_at_recall_3: 0.8491\n",
      "Epoch 7/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - loss: 0.0038 - precision_at_recall_3: 0.0932 - val_loss: 0.0012 - val_precision_at_recall_3: 0.9184\n",
      "Epoch 6/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0027 - precision_at_recall_3: 0.1271 - val_loss: 0.0019 - val_precision_at_recall_3: 0.8704\n",
      "\u001b[1m2673/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0010 - precision_at_recall_3: 0.8692Epoch 5/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 6.1263e-04 - precision_at_recall_3: 0.9119 - val_loss: 5.9168e-04 - val_precision_at_recall_3: 0.9583\n",
      "Epoch 16/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 9.8636e-04 - precision_at_recall_3: 0.8522 - val_loss: 0.0013 - val_precision_at_recall_3: 0.8545\n",
      "Epoch 8/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.0026 - precision_at_recall_3: 0.2196 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8846\n",
      "\u001b[1m1356/3973\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - loss: 0.0010 - precision_at_recall_3: 0.7657Epoch 7/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0030 - precision_at_recall_3: 0.1660 - val_loss: 0.0013 - val_precision_at_recall_3: 0.8704\n",
      "\u001b[1m2138/3973\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 9.1659e-04 - precision_at_recall_3: 0.6978Epoch 6/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 6.3982e-04 - precision_at_recall_3: 0.8205 - val_loss: 6.9526e-04 - val_precision_at_recall_3: 0.9091\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 8.8454e-04 - precision_at_recall_3: 0.6805 - val_loss: 8.7417e-04 - val_precision_at_recall_3: 0.8679\n",
      "Epoch 9/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0026 - precision_at_recall_3: 0.1412 - val_loss: 0.0010 - val_precision_at_recall_3: 0.8889\n",
      "Epoch 8/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - loss: 0.0022 - precision_at_recall_3: 0.1799 - val_loss: 0.0022 - val_precision_at_recall_3: 0.8364\n",
      "\u001b[1m 829/3973\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0023 - precision_at_recall_3: 0.4648Epoch 7/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 7.3911e-04 - precision_at_recall_3: 0.7771 - val_loss: 0.0011 - val_precision_at_recall_3: 0.8276\n",
      "Epoch 10/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/stepp - loss: 7.2506e-04 - precision_at_recall_3: 0.512\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0022 - precision_at_recall_3: 0.3935 - val_loss: 0.0015 - val_precision_at_recall_3: 0.8889\n",
      "Epoch 9/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0022 - precision_at_recall_3: 0.4299 - val_loss: 0.0016 - val_precision_at_recall_3: 0.8167\n",
      "Epoch 8/50\n",
      "\u001b[1m2020/3973\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 5.6033e-04 - precision_at_recall_3: 0.8098Epoch 1/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - loss: 0.0032 - precision_at_recall_3: 0.2834 - val_loss: 0.0028 - val_precision_at_recall_3: 0.8846\n",
      "Epoch 10/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 6.3169e-04 - precision_at_recall_3: 0.8088 - val_loss: 0.0010 - val_precision_at_recall_3: 0.8824\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - loss: 0.0028 - precision_at_recall_3: 0.2557 - val_loss: 0.0015 - val_precision_at_recall_3: 0.8305\n",
      "\u001b[1m 414/1242\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 4ms/stepEpoch 9/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/stepp - loss: 0.0020 - precision_at_recall_3: 0.372\n",
      "\u001b[1m3172/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0025 - precision_at_recall_3: 0.3098Epoch 1/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0061 - precision_at_recall_3: 0.0081 - val_loss: 0.0015 - val_precision_at_recall_3: 0.9020\n",
      "Epoch 2/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0026 - precision_at_recall_3: 0.2827 - val_loss: 9.7530e-04 - val_precision_at_recall_3: 0.8868\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.0024 - precision_at_recall_3: 0.3275 - val_loss: 0.0016 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 10/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.0093 - precision_at_recall_3: 0.0010.986\n",
      "\u001b[1m3180/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0077 - precision_at_recall_3: 0.0042Epoch 1/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.0017 - precision_at_recall_3: 0.1906 - val_loss: 0.0016 - val_precision_at_recall_3: 0.9020\n",
      "Epoch 3/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - loss: 0.0071 - precision_at_recall_3: 0.0050 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8727\n",
      "\u001b[1m   1/3973\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:28:29\u001b[0m 6s/step - loss: 0.0879 - precision_at_recall_3: 0.0000e+00Epoch 2/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0024 - precision_at_recall_3: 0.5429 - val_loss: 0.0016 - val_precision_at_recall_3: 0.8679\n",
      "\u001b[1m2243/3973\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.0017 - precision_at_recall_3: 0.4250Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0024 - precision_at_recall_3: 0.21\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0021 - precision_at_recall_3: 0.3198 - val_loss: 0.0016 - val_precision_at_recall_3: 0.9000\n",
      "Epoch 4/50\n",
      "\u001b[1m 144/3973\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 0.0010 - precision_at_recall_3: 0.1329    Epoch 1/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0024 - precision_at_recall_3: 0.1968 - val_loss: 0.0024 - val_precision_at_recall_3: 0.8491\n",
      "\u001b[1m 202/3973\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 0.0012 - precision_at_recall_3: 0.1979Epoch 3/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0046 - precision_at_recall_3: 0.0109 - val_loss: 0.0015 - val_precision_at_recall_3: 0.3538\n",
      "Epoch 2/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0018 - precision_at_recall_3: 0.1489 - val_loss: 0.0019 - val_precision_at_recall_3: 0.8462\n",
      "Epoch 5/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0025 - precision_at_recall_3: 0.2067 - val_loss: 0.0014 - val_precision_at_recall_3: 0.8421\n",
      "\u001b[1m 177/3973\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 2.5560e-04 - precision_at_recall_3: 0.5104Epoch 4/50\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - loss: 0.0044 - precision_at_recall_3: 0.0152 - val_loss: 9.1515e-04 - val_precision_at_recall_3: 0.9020\n",
      "\u001b[1m 428/3973\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.0012 - precision_at_recall_3: 0.2666Epoch 2/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.0026 - precision_at_recall_3: 0.1219 - val_loss: 0.0015 - val_precision_at_recall_3: 0.8519\n",
      "Epoch 3/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0025 - precision_at_recall_3: 0.1017 - val_loss: 0.0016 - val_precision_at_recall_3: 0.8491\n",
      "Epoch 5/50\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0011 - precision_at_recall_3: 0.6844 - val_loss: 9.8115e-04 - val_precision_at_recall_3: 0.8846\n",
      "Epoch 3/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0022 - precision_at_recall_3: 0.1168 - val_loss: 0.0015 - val_precision_at_recall_3: 0.8980\n",
      "Epoch 6/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0018 - precision_at_recall_3: 0.3018 - val_loss: 0.0015 - val_precision_at_recall_3: 0.8333\n",
      "Epoch 4/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0031 - precision_at_recall_3: 0.1165 - val_loss: 0.0048 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 6/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0026 - precision_at_recall_3: 0.1448 - val_loss: 0.0012 - val_precision_at_recall_3: 0.7188\n",
      "Epoch 5/50\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0011 - precision_at_recall_3: 0.6366 - val_loss: 6.6870e-04 - val_precision_at_recall_3: 0.9038\n",
      "Epoch 4/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - loss: 0.0011 - precision_at_recall_3: 0.7042 - val_loss: 8.0455e-04 - val_precision_at_recall_3: 0.9000\n",
      "Epoch 5/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 0.0024 - precision_at_recall_3: 0.3073 - val_loss: 0.0013 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 7/50\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - loss: 0.0014 - precision_at_recall_3: 0.5966 - val_loss: 6.7116e-04 - val_precision_at_recall_3: 0.9057\n",
      "Epoch 6/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 5ms/step - loss: 0.0015 - precision_at_recall_3: 0.3760 - val_loss: 0.0038 - val_precision_at_recall_3: 0.9167\n",
      "\u001b[1m 326/1987\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 6.8124e-04 - precision_at_recall_3: 0.6953Epoch 7/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0021 - precision_at_recall_3: 0.2623 - val_loss: 0.0015 - val_precision_at_recall_3: 0.8182\n",
      "Epoch 6/50\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 0.0010 - precision_at_recall_3: 0.5514 - val_loss: 0.0010 - val_precision_at_recall_3: 0.9000\n",
      "Epoch 7/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0021 - precision_at_recall_3: 0.3275 - val_loss: 0.0022 - val_precision_at_recall_3: 0.8571\n",
      "\u001b[1m3107/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0022 - precision_at_recall_3: 0.2732Epoch 8/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0022 - precision_at_recall_3: 0.2610 - val_loss: 0.0025 - val_precision_at_recall_3: 0.7857\n",
      "Epoch 8/50\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 0.0011 - precision_at_recall_3: 0.5433 - val_loss: 8.9408e-04 - val_precision_at_recall_3: 0.8909\n",
      "\u001b[1m 214/3973\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.0020 - precision_at_recall_3: 0.5343Epoch 8/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0023 - precision_at_recall_3: 0.0927 - val_loss: 0.0014 - val_precision_at_recall_3: 0.7759\n",
      "Epoch 7/50\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 0.0011 - precision_at_recall_3: 0.6487 - val_loss: 7.2700e-04 - val_precision_at_recall_3: 0.8929\n",
      "Epoch 9/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0027 - precision_at_recall_3: 0.2245 - val_loss: 0.0051 - val_precision_at_recall_3: 0.9167\n",
      "\u001b[1m 441/3973\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 0.0018 - precision_at_recall_3: 0.2385Epoch 9/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - loss: 0.0017 - precision_at_recall_3: 0.2218 - val_loss: 0.0027 - val_precision_at_recall_3: 0.7188\n",
      "Epoch 8/50\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - loss: 9.2916e-04 - precision_at_recall_3: 0.7340 - val_loss: 7.7105e-04 - val_precision_at_recall_3: 0.9020\n",
      "\u001b[1m 102/3973\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0015 - precision_at_recall_3: 0.4907Epoch 10/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - loss: 9.9532e-04 - precision_at_recall_3: 0.7702 - val_loss: 8.1510e-04 - val_precision_at_recall_3: 0.8889\n",
      "Epoch 11/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step - loss: 0.0021 - precision_at_recall_3: 0.5096 - val_loss: 0.0027 - val_precision_at_recall_3: 0.8491\n",
      "Epoch 9/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.0018 - precision_at_recall_3: 0.1567 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8491\n",
      "\u001b[1m1946/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.6229e-04 - precision_at_recall_3: 0.6324Epoch 9/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5ms/step - loss: 0.0024 - precision_at_recall_3: 0.7299 - val_loss: 0.0032 - val_precision_at_recall_3: 0.6438\n",
      "Epoch 10/50\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - loss: 9.6501e-04 - precision_at_recall_3: 0.6348 - val_loss: 9.4746e-04 - val_precision_at_recall_3: 0.9000\n",
      "\u001b[1m1394/3973\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 0.0015 - precision_at_recall_3: 0.5124Epoch 12/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 8.0327e-04 - precision_at_recall_3: 0.8033 - val_loss: 9.9720e-04 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 13/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 0.0021 - precision_at_recall_3: 0.5604 - val_loss: 0.0019 - val_precision_at_recall_3: 0.8491\n",
      "Epoch 10/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0016 - precision_at_recall_3: 0.2982 - val_loss: 0.0010 - val_precision_at_recall_3: 0.6104\n",
      "Epoch 10/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0023 - precision_at_recall_3: 0.1300 - val_loss: 0.0016 - val_precision_at_recall_3: 0.8868\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 9.6101e-04 - precision_at_recall_3: 0.7057 - val_loss: 0.0011 - val_precision_at_recall_3: 0.9057\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/stepep - loss: 0.0015 - precision_at_recall_3: 0.305\n",
      "\u001b[1m2263/3973\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.0016 - precision_at_recall_3: 0.1899Epoch 1/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0018 - precision_at_recall_3: 0.3014 - val_loss: 0.0020 - val_precision_at_recall_3: 0.2394\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 0.0016 - precision_at_recall_3: 0.2116 - val_loss: 0.0019 - val_precision_at_recall_3: 0.7121\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0045 - precision_at_recall_3: 0.029\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.0044 - precision_at_recall_3: 0.0238 - val_loss: 8.7760e-04 - val_precision_at_recall_3: 0.8596\n",
      "Epoch 2/100\n",
      "\u001b[1m 177/1242\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 3ms/stepEpoch 1/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m 107/1987\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 9.6431e-04 - precision_at_recall_3: 0.4837Epoch 1/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0081 - precision_at_recall_3: 0.000\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 0.0013 - precision_at_recall_3: 0.3930 - val_loss: 0.0010 - val_precision_at_recall_3: 0.8727\n",
      "Epoch 3/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 0.0060 - precision_at_recall_3: 0.0132 - val_loss: 0.0011 - val_precision_at_recall_3: 0.8868\n",
      "Epoch 2/100\n",
      "\u001b[1m1217/1987\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0079 - precision_at_recall_3: 0.0084Epoch 1/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 0.0061 - precision_at_recall_3: 0.0216 - val_loss: 0.0014 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 2/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 0.0012 - precision_at_recall_3: 0.7347 - val_loss: 7.8401e-04 - val_precision_at_recall_3: 0.8750\n",
      "\u001b[1m 302/1987\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.0021 - precision_at_recall_3: 0.1065Epoch 4/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 0.0012 - precision_at_recall_3: 0.8244 - val_loss: 9.6349e-04 - val_precision_at_recall_3: 0.9200\n",
      "\u001b[1m  39/1987\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 8.8459e-04 - precision_at_recall_3: 0.8479Epoch 3/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - loss: 0.0015 - precision_at_recall_3: 0.3930 - val_loss: 0.0011 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 3/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - loss: 0.0012 - precision_at_recall_3: 0.7276 - val_loss: 0.0010 - val_precision_at_recall_3: 0.8679\n",
      "Epoch 5/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - loss: 0.0012 - precision_at_recall_3: 0.6571 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8868\n",
      "Epoch 4/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.0067 - precision_at_recall_3: 0.0138 - val_loss: 0.0020 - val_precision_at_recall_3: 0.8491\n",
      "\u001b[1m 274/1987\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 8.6387e-04 - precision_at_recall_3: 0.5956Epoch 2/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 0.0010 - precision_at_recall_3: 0.8352 - val_loss: 8.9443e-04 - val_precision_at_recall_3: 0.8727\n",
      "Epoch 6/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 0.0011 - precision_at_recall_3: 0.7520 - val_loss: 9.6608e-04 - val_precision_at_recall_3: 0.8868\n",
      "Epoch 5/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 0.0016 - precision_at_recall_3: 0.3465 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8679\n",
      "\u001b[1m 310/1987\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.0016 - precision_at_recall_3: 0.1700Epoch 3/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - loss: 0.0011 - precision_at_recall_3: 0.8147 - val_loss: 0.0013 - val_precision_at_recall_3: 0.8545\n",
      "Epoch 4/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 0.0011 - precision_at_recall_3: 0.6380 - val_loss: 0.0011 - val_precision_at_recall_3: 0.8727\n",
      "Epoch 7/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 0.0015 - precision_at_recall_3: 0.4348 - val_loss: 0.0014 - val_precision_at_recall_3: 0.9000\n",
      "Epoch 6/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0011 - precision_at_recall_3: 0.4888 - val_loss: 0.0010 - val_precision_at_recall_3: 0.8704\n",
      "\u001b[1m 524/1987\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.0011 - precision_at_recall_3: 0.8496Epoch 4/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 0.0015 - precision_at_recall_3: 0.6901 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8679\n",
      "Epoch 5/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 9.9709e-04 - precision_at_recall_3: 0.8263 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8596\n",
      "Epoch 8/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 0.0011 - precision_at_recall_3: 0.6403 - val_loss: 0.0015 - val_precision_at_recall_3: 0.8868\n",
      "Epoch 7/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - loss: 9.2138e-04 - precision_at_recall_3: 0.7126 - val_loss: 0.0016 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 6/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 9.6581e-04 - precision_at_recall_3: 0.7763 - val_loss: 7.5824e-04 - val_precision_at_recall_3: 0.8846\n",
      "Epoch 9/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 0.0012 - precision_at_recall_3: 0.5433 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 5/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 6.7038e-04 - precision_at_recall_3: 0.7312 - val_loss: 0.0016 - val_precision_at_recall_3: 0.9167\n",
      "\u001b[1m  17/1987\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0011 - precision_at_recall_3: 0.5882           Epoch 8/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 0.0013 - precision_at_recall_3: 0.6140 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 7/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 8.5165e-04 - precision_at_recall_3: 0.8153 - val_loss: 8.3786e-04 - val_precision_at_recall_3: 0.9020\n",
      "Epoch 10/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 0.0011 - precision_at_recall_3: 0.6819 - val_loss: 0.0011 - val_precision_at_recall_3: 0.8545\n",
      "Epoch 6/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - loss: 0.0013 - precision_at_recall_3: 0.7181 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 8/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.0013 - precision_at_recall_3: 0.7280 - val_loss: 0.0014 - val_precision_at_recall_3: 0.8980\n",
      "Epoch 9/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 7.0267e-04 - precision_at_recall_3: 0.7638 - val_loss: 0.0011 - val_precision_at_recall_3: 0.8727\n",
      "\u001b[1m 121/1987\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 3.8325e-04 - precision_at_recall_3: 0.9230Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - loss: 9.2266e-04 - precision_at_recall_3: 0.7765 - val_loss: 0.0012 - val_precision_at_recall_3: 0.7895\n",
      "Epoch 7/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0010 - precision_at_recall_3: 0.6882 - val_loss: 0.0013 - val_precision_at_recall_3: 0.8654\n",
      "Epoch 9/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 7.4571e-04 - precision_at_recall_3: 0.8502 - val_loss: 0.0012 - val_precision_at_recall_3: 0.9000\n",
      "Epoch 10/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0013 - precision_at_recall_3: 0.5978 - val_loss: 0.0013 - val_precision_at_recall_3: 0.8491\n",
      "Epoch 10/100\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/stepep - loss: 0.0012 - precision_at_recall_3: 0.350.731\n",
      "\u001b[1m1443/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0010 - precision_at_recall_3: 0.7167Epoch 1/50\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 9.9721e-04 - precision_at_recall_3: 0.7322 - val_loss: 0.0012 - val_precision_at_recall_3: 0.9167\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.0012 - precision_at_recall_3: 0.5862 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8545\n",
      "Epoch 8/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 9.4852e-04 - precision_at_recall_3: 0.7335 - val_loss: 0.0013 - val_precision_at_recall_3: 0.8679\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/stepep - loss: 0.0011 - precision_at_recall_3: 0.65\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/steps: 0.2558 - precision_at_recall_3: 0.0011     777\n",
      "\u001b[1m1366/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0011 - precision_at_recall_3: 0.6395Epoch 1/50\n",
      "\u001b[1m1001/3973\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 0.0200 - precision_at_recall_3: 0.0018Epoch 1/50\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 0.0011 - precision_at_recall_3: 0.6675 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8679\n",
      "Epoch 9/100\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 9.2406e-04 - precision_at_recall_3: 0.6162 - val_loss: 0.0011 - val_precision_at_recall_3: 0.8679\n",
      "\u001b[1m1448/3973\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.0085 - precision_at_recall_3: 0.0035Epoch 10/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0080 - precision_at_recall_3: 0.0061 - val_loss: 8.5668e-04 - val_precision_at_recall_3: 0.9038\n",
      "\u001b[1m2668/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0078 - precision_at_recall_3: 0.0128Epoch 2/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0061 - precision_at_recall_3: 0.0165 - val_loss: 9.8766e-04 - val_precision_at_recall_3: 0.8679\n",
      "\u001b[1m 208/1987\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 8.2186e-04 - precision_at_recall_3: 0.9053Epoch 2/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step - loss: 0.0050 - precision_at_recall_3: 0.0175 - val_loss: 0.0011 - val_precision_at_recall_3: 0.9000\n",
      "Epoch 2/50\n",
      "\u001b[1m1987/1987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 8.3831e-04 - precision_at_recall_3: 0.7103 - val_loss: 0.0010 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0013 - precision_at_recall_3: 0.6649 - val_loss: 0.0011 - val_precision_at_recall_3: 0.9057\n",
      "Epoch 3/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0012 - precision_at_recall_3: 0.5298 - val_loss: 9.0566e-04 - val_precision_at_recall_3: 0.8727\n",
      "Epoch 3/50\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/steptep - loss: 5.3523e-04 - precision_at_recall_3: 0.840\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0013 - precision_at_recall_3: 0.5173 - val_loss: 9.1932e-04 - val_precision_at_recall_3: 0.9038\n",
      "Epoch 3/50\n",
      "\u001b[1m  76/3973\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 8.6775e-04 - precision_at_recall_3: 0.0736Epoch 1/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0012 - precision_at_recall_3: 0.7311 - val_loss: 7.9667e-04 - val_precision_at_recall_3: 0.9038\n",
      "\u001b[1m 717/3973\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 0.0012 - precision_at_recall_3: 0.5693Epoch 4/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 8.7529e-04 - precision_at_recall_3: 0.8222 - val_loss: 7.7721e-04 - val_precision_at_recall_3: 0.8750\n",
      "Epoch 4/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0011 - precision_at_recall_3: 0.6625 - val_loss: 0.0010 - val_precision_at_recall_3: 0.9000\n",
      "Epoch 4/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 5ms/step - loss: 0.0012 - precision_at_recall_3: 0.7376 - val_loss: 6.7294e-04 - val_precision_at_recall_3: 0.9074\n",
      "Epoch 5/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6ms/step - loss: 0.0043 - precision_at_recall_3: 0.0325 - val_loss: 0.0020 - val_precision_at_recall_3: 0.4742\n",
      "\u001b[1m3164/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 8.5301e-04 - precision_at_recall_3: 0.7553Epoch 2/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 8.5520e-04 - precision_at_recall_3: 0.7566 - val_loss: 9.1838e-04 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 5/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 8.7685e-04 - precision_at_recall_3: 0.8027 - val_loss: 0.0011 - val_precision_at_recall_3: 0.9000\n",
      "Epoch 5/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 9.0633e-04 - precision_at_recall_3: 0.7865 - val_loss: 6.8283e-04 - val_precision_at_recall_3: 0.9074\n",
      "Epoch 6/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0010 - precision_at_recall_3: 0.7751 - val_loss: 9.5894e-04 - val_precision_at_recall_3: 0.8545\n",
      "\u001b[1m 895/3973\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 0.0013 - precision_at_recall_3: 0.4284Epoch 6/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 8.7846e-04 - precision_at_recall_3: 0.7332 - val_loss: 0.0011 - val_precision_at_recall_3: 0.9000\n",
      "\u001b[1m3077/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0014 - precision_at_recall_3: 0.3014Epoch 6/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 8.6647e-04 - precision_at_recall_3: 0.7876 - val_loss: 6.0126e-04 - val_precision_at_recall_3: 0.8909\n",
      "\u001b[1m2747/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0010 - precision_at_recall_3: 0.4730Epoch 7/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 6ms/step - loss: 0.0014 - precision_at_recall_3: 0.3147 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 3/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 9.8742e-04 - precision_at_recall_3: 0.5739 - val_loss: 9.2355e-04 - val_precision_at_recall_3: 0.8750\n",
      "Epoch 7/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0010 - precision_at_recall_3: 0.6043 - val_loss: 8.9153e-04 - val_precision_at_recall_3: 0.9038\n",
      "Epoch 7/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - loss: 0.0012 - precision_at_recall_3: 0.7636 - val_loss: 0.0011 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 4/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 9.2803e-04 - precision_at_recall_3: 0.6350 - val_loss: 0.0010 - val_precision_at_recall_3: 0.8868\n",
      "Epoch 8/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - loss: 6.3354e-04 - precision_at_recall_3: 0.8407 - val_loss: 9.0916e-04 - val_precision_at_recall_3: 0.9020\n",
      "Epoch 8/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step - loss: 6.8338e-04 - precision_at_recall_3: 0.8505 - val_loss: 6.5346e-04 - val_precision_at_recall_3: 0.9074\n",
      "Epoch 8/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 9.3303e-04 - precision_at_recall_3: 0.7640 - val_loss: 6.8788e-04 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 9/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - loss: 0.0013 - precision_at_recall_3: 0.7427 - val_loss: 0.0010 - val_precision_at_recall_3: 0.8596\n",
      "\u001b[1m2278/3973\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 9.5706e-04 - precision_at_recall_3: 0.8217Epoch 5/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - loss: 8.7815e-04 - precision_at_recall_3: 0.7234 - val_loss: 7.8440e-04 - val_precision_at_recall_3: 0.9375\n",
      "Epoch 9/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - loss: 9.4144e-04 - precision_at_recall_3: 0.8312 - val_loss: 0.0010 - val_precision_at_recall_3: 0.8868\n",
      "Epoch 9/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 7.7849e-04 - precision_at_recall_3: 0.8344 - val_loss: 7.9278e-04 - val_precision_at_recall_3: 0.8846\n",
      "Epoch 10/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 6.8857e-04 - precision_at_recall_3: 0.8410 - val_loss: 0.0014 - val_precision_at_recall_3: 0.9000\n",
      "Epoch 10/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - loss: 9.5569e-04 - precision_at_recall_3: 0.7446 - val_loss: 7.2136e-04 - val_precision_at_recall_3: 0.9184\n",
      "\u001b[1m3075/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0012 - precision_at_recall_3: 0.5177Epoch 10/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 8.5383e-04 - precision_at_recall_3: 0.8248 - val_loss: 7.8018e-04 - val_precision_at_recall_3: 0.8750\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step - loss: 0.0012 - precision_at_recall_3: 0.5788 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8333\n",
      "Epoch 6/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 7.4648e-04 - precision_at_recall_3: 0.784\n",
      "\u001b[1m3746/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.2803e-04 - precision_at_recall_3: 0.7805Epoch 1/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 8.2762e-04 - precision_at_recall_3: 0.7822 - val_loss: 9.7424e-04 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 7.9176e-04 - precision_at_recall_3: 0.7991 - val_loss: 7.5679e-04 - val_precision_at_recall_3: 0.9200\n",
      "Epoch 11/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/stepp - loss: 4.2947e-04 - precision_at_recall_3: 0.92\n",
      "\u001b[1m1523/3973\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 4.4369e-04 - precision_at_recall_3: 0.9252Epoch 1/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - loss: 0.0103 - precision_at_recall_3: 0.0045 - val_loss: 9.3868e-04 - val_precision_at_recall_3: 0.8846\n",
      "Epoch 2/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 6.1487e-04 - precision_at_recall_3: 0.8842 - val_loss: 6.0858e-04 - val_precision_at_recall_3: 0.8929\n",
      "\u001b[1m2238/3973\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.0108 - precision_at_recall_3: 0.0043Epoch 12/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step - loss: 8.8336e-04 - precision_at_recall_3: 0.7938 - val_loss: 0.0015 - val_precision_at_recall_3: 0.8393\n",
      "Epoch 7/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 6ms/step - loss: 0.0077 - precision_at_recall_3: 0.0057 - val_loss: 8.9741e-04 - val_precision_at_recall_3: 0.9074\n",
      "Epoch 2/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 7.2462e-04 - precision_at_recall_3: 0.7958 - val_loss: 5.6768e-04 - val_precision_at_recall_3: 0.9583\n",
      "Epoch 13/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 0.0013 - precision_at_recall_3: 0.2562 - val_loss: 9.4238e-04 - val_precision_at_recall_3: 0.8654\n",
      "Epoch 3/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - loss: 9.1434e-04 - precision_at_recall_3: 0.6565 - val_loss: 8.5161e-04 - val_precision_at_recall_3: 0.9184\n",
      "Epoch 8/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - loss: 0.0016 - precision_at_recall_3: 0.4704 - val_loss: 8.9980e-04 - val_precision_at_recall_3: 0.9020\n",
      "Epoch 3/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 7.2311e-04 - precision_at_recall_3: 0.8720 - val_loss: 8.3421e-04 - val_precision_at_recall_3: 0.8333\n",
      "Epoch 14/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 6.9352e-04 - precision_at_recall_3: 0.7093 - val_loss: 9.3962e-04 - val_precision_at_recall_3: 0.9000\n",
      "Epoch 9/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0017 - precision_at_recall_3: 0.3850 - val_loss: 9.8386e-04 - val_precision_at_recall_3: 0.9057\n",
      "Epoch 4/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 6.9621e-04 - precision_at_recall_3: 0.7673 - val_loss: 6.9906e-04 - val_precision_at_recall_3: 0.9574\n",
      "Epoch 15/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 6ms/step - loss: 0.0011 - precision_at_recall_3: 0.8307 - val_loss: 0.0010 - val_precision_at_recall_3: 0.8333\n",
      "Epoch 4/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 8.4167e-04 - precision_at_recall_3: 0.7890 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 10/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0014 - precision_at_recall_3: 0.6282 - val_loss: 8.7382e-04 - val_precision_at_recall_3: 0.9000\n",
      "\u001b[1m1164/3973\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 8.7613e-04 - precision_at_recall_3: 0.8269Epoch 5/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 7.1141e-04 - precision_at_recall_3: 0.8492 - val_loss: 6.7245e-04 - val_precision_at_recall_3: 0.8909\n",
      "Epoch 16/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - loss: 8.8627e-04 - precision_at_recall_3: 0.8391 - val_loss: 0.0013 - val_precision_at_recall_3: 0.8448\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0020 - precision_at_recall_3: 0.6092 - val_loss: 7.1407e-04 - val_precision_at_recall_3: 0.9074\n",
      "\u001b[1m 377/1242\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 4ms/stepEpoch 6/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 8.9213e-04 - precision_at_recall_3: 0.63\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 4.5809e-04 - precision_at_recall_3: 0.8286 - val_loss: 7.7851e-04 - val_precision_at_recall_3: 0.9000\n",
      "Epoch 17/50\n",
      "\u001b[1m1028/3973\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 4.5163e-04 - precision_at_recall_3: 0.8814Epoch 1/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 5ms/step - loss: 9.4359e-04 - precision_at_recall_3: 0.6128 - val_loss: 8.7633e-04 - val_precision_at_recall_3: 0.8679\n",
      "Epoch 5/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0013 - precision_at_recall_3: 0.5480 - val_loss: 9.9841e-04 - val_precision_at_recall_3: 0.8909\n",
      "\u001b[1m1354/3973\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - loss: 0.0083 - precision_at_recall_3: 0.0028Epoch 7/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 6.1577e-04 - precision_at_recall_3: 0.8861 - val_loss: 7.0702e-04 - val_precision_at_recall_3: 0.8846\n",
      "Epoch 18/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 8.2231e-04 - precision_at_recall_3: 0.8049 - val_loss: 9.1158e-04 - val_precision_at_recall_3: 0.8393\n",
      "Epoch 6/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0050 - precision_at_recall_3: 0.0108 - val_loss: 0.0016 - val_precision_at_recall_3: 0.8519\n",
      "\u001b[1m3769/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - precision_at_recall_3: 0.7662Epoch 2/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0012 - precision_at_recall_3: 0.7598 - val_loss: 0.0011 - val_precision_at_recall_3: 0.8868\n",
      "Epoch 8/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 5.9065e-04 - precision_at_recall_3: 0.9234 - val_loss: 8.6232e-04 - val_precision_at_recall_3: 0.9583\n",
      "\u001b[1m2852/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 7.0028e-04 - precision_at_recall_3: 0.8581Epoch 19/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 7.6482e-04 - precision_at_recall_3: 0.8342 - val_loss: 9.3426e-04 - val_precision_at_recall_3: 0.8545\n",
      "Epoch 7/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 0.0012 - precision_at_recall_3: 0.6639 - val_loss: 9.6651e-04 - val_precision_at_recall_3: 0.9057\n",
      "Epoch 9/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 6.6576e-04 - precision_at_recall_3: 0.8609 - val_loss: 6.7464e-04 - val_precision_at_recall_3: 0.9375\n",
      "Epoch 20/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 4ms/step - loss: 0.0013 - precision_at_recall_3: 0.6255 - val_loss: 0.0011 - val_precision_at_recall_3: 0.8679\n",
      "Epoch 3/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0013 - precision_at_recall_3: 0.5688 - val_loss: 8.8461e-04 - val_precision_at_recall_3: 0.8909\n",
      "Epoch 10/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - loss: 8.2429e-04 - precision_at_recall_3: 0.8831 - val_loss: 8.1632e-04 - val_precision_at_recall_3: 0.8036\n",
      "\u001b[1m1608/3973\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - loss: 0.0012 - precision_at_recall_3: 0.4812Epoch 21/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 6ms/step - loss: 0.0014 - precision_at_recall_3: 0.3754 - val_loss: 8.2505e-04 - val_precision_at_recall_3: 0.8704\n",
      "\u001b[1m3326/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 6.1283e-04 - precision_at_recall_3: 0.8285Epoch 4/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 6ms/step - loss: 9.7684e-04 - precision_at_recall_3: 0.7476 - val_loss: 0.0011 - val_precision_at_recall_3: 0.8545\n",
      "\u001b[1m 152/3973\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 6.9823e-04 - precision_at_recall_3: 0.7304Epoch 8/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 6ms/step - loss: 0.0013 - precision_at_recall_3: 0.4790 - val_loss: 8.7231e-04 - val_precision_at_recall_3: 0.9020\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 6.0274e-04 - precision_at_recall_3: 0.8338 - val_loss: 9.4000e-04 - val_precision_at_recall_3: 0.9412\n",
      "\u001b[1m 184/1242\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2ms/stepEpoch 22/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0012 - precision_at_recall_3: 0.540.853\n",
      "\u001b[1m1915/3973\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 3.6750e-04 - precision_at_recall_3: 0.8483Epoch 1/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0012 - precision_at_recall_3: 0.5723 - val_loss: 0.0017 - val_precision_at_recall_3: 0.8750\n",
      "Epoch 5/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 4.2584e-04 - precision_at_recall_3: 0.8681 - val_loss: 8.6798e-04 - val_precision_at_recall_3: 0.9038\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0017 - precision_at_recall_3: 0.4757 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8868\n",
      "Epoch 6/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - loss: 0.0061 - precision_at_recall_3: 0.0077 - val_loss: 0.0011 - val_precision_at_recall_3: 0.9000\n",
      "Epoch 2/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.0011 - precision_at_recall_3: 0.7428.9\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 4ms/step - loss: 0.0011 - precision_at_recall_3: 0.7433 - val_loss: 0.0011 - val_precision_at_recall_3: 0.8727\n",
      "Epoch 9/50\n",
      "\u001b[1m2502/3973\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.0019 - precision_at_recall_3: 0.2405Epoch 1/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0013 - precision_at_recall_3: 0.6516 - val_loss: 0.0013 - val_precision_at_recall_3: 0.8364\n",
      "Epoch 7/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0018 - precision_at_recall_3: 0.2736 - val_loss: 0.0011 - val_precision_at_recall_3: 0.9167\n",
      "Epoch 3/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 8.7561e-04 - precision_at_recall_3: 0.7073 - val_loss: 9.2247e-04 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 10/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0012 - precision_at_recall_3: 0.6400 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 8/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0015 - precision_at_recall_3: 0.4278 - val_loss: 9.7964e-04 - val_precision_at_recall_3: 0.9038\n",
      "Epoch 4/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0046 - precision_at_recall_3: 0.0153 - val_loss: 0.0021 - val_precision_at_recall_3: 0.8545\n",
      "Epoch 2/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - loss: 7.1146e-04 - precision_at_recall_3: 0.8081 - val_loss: 9.0431e-04 - val_precision_at_recall_3: 0.8654\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0018 - precision_at_recall_3: 0.379\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0015 - precision_at_recall_3: 0.3903 - val_loss: 0.0012 - val_precision_at_recall_3: 0.9200\n",
      "Epoch 5/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0012 - precision_at_recall_3: 0.7362 - val_loss: 9.1049e-04 - val_precision_at_recall_3: 0.8750\n",
      "Epoch 9/100\n",
      "\u001b[1m 310/3973\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0018 - precision_at_recall_3: 0.5746Epoch 1/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0018 - precision_at_recall_3: 0.3586 - val_loss: 0.0016 - val_precision_at_recall_3: 0.8545\n",
      "Epoch 3/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0014 - precision_at_recall_3: 0.2525 - val_loss: 0.0016 - val_precision_at_recall_3: 0.8868\n",
      "Epoch 6/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0013 - precision_at_recall_3: 0.6257 - val_loss: 0.0014 - val_precision_at_recall_3: 0.8679\n",
      "\u001b[1m2451/3973\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0070 - precision_at_recall_3: 0.0059Epoch 10/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0013 - precision_at_recall_3: 0.4704 - val_loss: 0.0010 - val_precision_at_recall_3: 0.8704\n",
      "\u001b[1m2881/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0064 - precision_at_recall_3: 0.0069Epoch 4/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0055 - precision_at_recall_3: 0.0113 - val_loss: 0.0015 - val_precision_at_recall_3: 0.8654\n",
      "Epoch 2/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0012 - precision_at_recall_3: 0.5726 - val_loss: 0.0015 - val_precision_at_recall_3: 0.9000\n",
      "Epoch 7/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0015 - precision_at_recall_3: 0.4633 - val_loss: 0.0015 - val_precision_at_recall_3: 0.8545\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - loss: 0.0015 - precision_at_recall_3: 0.4830 - val_loss: 0.0013 - val_precision_at_recall_3: 0.8654\n",
      "Epoch 5/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0014 - precision_at_recall_3: 0.441\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 0.0019 - precision_at_recall_3: 0.0816 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8654\n",
      "Epoch 3/100\n",
      "\u001b[1m 410/3973\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 6.5452e-04 - precision_at_recall_3: 0.7289Epoch 1/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0014 - precision_at_recall_3: 0.4418 - val_loss: 0.0011 - val_precision_at_recall_3: 0.8868\n",
      "Epoch 8/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0015 - precision_at_recall_3: 0.3339 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 6/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0011 - precision_at_recall_3: 0.8077 - val_loss: 0.0025 - val_precision_at_recall_3: 0.8846\n",
      "Epoch 9/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - loss: 0.0049 - precision_at_recall_3: 0.0039 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8824\n",
      "\u001b[1m 882/3973\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 0.0013 - precision_at_recall_3: 0.3638Epoch 2/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - loss: 0.0013 - precision_at_recall_3: 0.6539 - val_loss: 0.0014 - val_precision_at_recall_3: 0.8545\n",
      "\u001b[1m  10/3973\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - loss: 8.9342e-05 - precision_at_recall_3: 0.4000      Epoch 4/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - loss: 0.0013 - precision_at_recall_3: 0.5923 - val_loss: 0.0010 - val_precision_at_recall_3: 0.8727\n",
      "\u001b[1m3257/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0015 - precision_at_recall_3: 0.4662Epoch 7/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0014 - precision_at_recall_3: 0.4708 - val_loss: 0.0014 - val_precision_at_recall_3: 0.9000\n",
      "\u001b[1m3801/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0015 - precision_at_recall_3: 0.4593Epoch 10/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - loss: 0.0015 - precision_at_recall_3: 0.4582 - val_loss: 0.0018 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 5/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0019 - precision_at_recall_3: 0.1713 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8909\n",
      "Epoch 3/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - loss: 7.4271e-04 - precision_at_recall_3: 0.8412 - val_loss: 0.0023 - val_precision_at_recall_3: 0.8868\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0013 - precision_at_recall_3: 0.6442 - val_loss: 0.0016 - val_precision_at_recall_3: 0.8679\n",
      "Epoch 8/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/stepp - loss: 0.0013 - precision_at_recall_3: 0.63\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0019 - precision_at_recall_3: 0.3363 - val_loss: 0.0014 - val_precision_at_recall_3: 0.8889\n",
      "Epoch 4/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - loss: 0.0012 - precision_at_recall_3: 0.5603 - val_loss: 0.0011 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 6/100\n",
      "\u001b[1m 447/3973\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0025 - precision_at_recall_3: 0.3972Epoch 1/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - loss: 0.0014 - precision_at_recall_3: 0.6117 - val_loss: 0.0011 - val_precision_at_recall_3: 0.8571\n",
      "\u001b[1m1287/3973\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 0.0076 - precision_at_recall_3: 0.0024Epoch 9/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0016 - precision_at_recall_3: 0.4217 - val_loss: 0.0011 - val_precision_at_recall_3: 0.8824\n",
      "Epoch 7/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - loss: 0.0024 - precision_at_recall_3: 0.0860 - val_loss: 0.0011 - val_precision_at_recall_3: 0.9038\n",
      "Epoch 5/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0045 - precision_at_recall_3: 0.0209 - val_loss: 0.0022 - val_precision_at_recall_3: 0.8519\n",
      "Epoch 2/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0011 - precision_at_recall_3: 0.5805 - val_loss: 0.0013 - val_precision_at_recall_3: 0.8571\n",
      "\u001b[1m2876/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0014 - precision_at_recall_3: 0.4280Epoch 10/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0013 - precision_at_recall_3: 0.4626 - val_loss: 0.0010 - val_precision_at_recall_3: 0.8704\n",
      "\u001b[1m1293/3973\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 0.0013 - precision_at_recall_3: 0.6154Epoch 8/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0014 - precision_at_recall_3: 0.3776 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8868\n",
      "Epoch 6/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0024 - precision_at_recall_3: 0.1301 - val_loss: 0.0030 - val_precision_at_recall_3: 0.8704\n",
      "\u001b[1m3740/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0013 - precision_at_recall_3: 0.6192Epoch 3/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0013 - precision_at_recall_3: 0.6186 - val_loss: 0.0014 - val_precision_at_recall_3: 0.8704\n",
      "\u001b[1m3635/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0012 - precision_at_recall_3: 0.6589Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - loss: 0.0012 - precision_at_recall_3: 0.6432 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8679\n",
      "Epoch 9/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.0018 - precision_at_recall_3: 0.537\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0016 - precision_at_recall_3: 0.4851 - val_loss: 9.3702e-04 - val_precision_at_recall_3: 0.9057\n",
      "Epoch 7/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0017 - precision_at_recall_3: 0.5438 - val_loss: 0.0015 - val_precision_at_recall_3: 0.8364\n",
      "Epoch 4/50\n",
      "\u001b[1m2275/3973\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.0012 - precision_at_recall_3: 0.8082Epoch 1/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0013 - precision_at_recall_3: 0.7931 - val_loss: 0.0013 - val_precision_at_recall_3: 0.8679\n",
      "Epoch 10/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0015 - precision_at_recall_3: 0.3957 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8889\n",
      "Epoch 8/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0014 - precision_at_recall_3: 0.6216 - val_loss: 0.0013 - val_precision_at_recall_3: 0.8679\n",
      "Epoch 5/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0051 - precision_at_recall_3: 0.0098 - val_loss: 0.0018 - val_precision_at_recall_3: 0.4835\n",
      "\u001b[1m3640/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0013 - precision_at_recall_3: 0.3806Epoch 2/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - loss: 0.0013 - precision_at_recall_3: 0.3830 - val_loss: 0.0016 - val_precision_at_recall_3: 0.8679\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0016 - precision_at_recall_3: 0.2870 - val_loss: 0.0010 - val_precision_at_recall_3: 0.9057\n",
      "Epoch 9/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/stepp - loss: 0.0011 - precision_at_recall_3: 0.576\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0018 - precision_at_recall_3: 0.4430 - val_loss: 0.0015 - val_precision_at_recall_3: 0.8596\n",
      "\u001b[1m1289/3973\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 0.0011 - precision_at_recall_3: 0.5749Epoch 6/50\n",
      "\u001b[1m3159/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0014 - precision_at_recall_3: 0.5700Epoch 1/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0020 - precision_at_recall_3: 0.2465 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8846\n",
      "\u001b[1m3430/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0015 - precision_at_recall_3: 0.5530Epoch 3/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0015 - precision_at_recall_3: 0.5203 - val_loss: 0.0017 - val_precision_at_recall_3: 0.9020\n",
      "Epoch 10/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0018 - precision_at_recall_3: 0.3241 - val_loss: 0.0025 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 7/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0021 - precision_at_recall_3: 0.2241 - val_loss: 0.0029 - val_precision_at_recall_3: 0.9020\n",
      "Epoch 4/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.0022 - precision_at_recall_3: 0.2106 - val_loss: 0.0025 - val_precision_at_recall_3: 0.8889\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6ms/step - loss: 0.0070 - precision_at_recall_3: 0.0059 - val_loss: 0.0028 - val_precision_at_recall_3: 0.8545\n",
      "Epoch 2/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/stepp - loss: 6.3534e-04 - precision_at_recall_3: 0.502\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0015 - precision_at_recall_3: 0.2352 - val_loss: 0.0013 - val_precision_at_recall_3: 0.8136\n",
      "Epoch 8/50\n",
      "\u001b[1m2879/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0019 - precision_at_recall_3: 0.5517Epoch 1/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0020 - precision_at_recall_3: 0.4917 - val_loss: 0.0014 - val_precision_at_recall_3: 0.8491\n",
      "Epoch 5/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0017 - precision_at_recall_3: 0.3132 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8654\n",
      "Epoch 3/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0014 - precision_at_recall_3: 0.5757 - val_loss: 0.0017 - val_precision_at_recall_3: 0.8364\n",
      "Epoch 9/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0047 - precision_at_recall_3: 0.0154 - val_loss: 0.0017 - val_precision_at_recall_3: 0.8545\n",
      "Epoch 2/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0022 - precision_at_recall_3: 0.2698 - val_loss: 0.0014 - val_precision_at_recall_3: 0.9038\n",
      "Epoch 6/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 5ms/step - loss: 0.0015 - precision_at_recall_3: 0.5304 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8679\n",
      "Epoch 4/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 5ms/step - loss: 0.0015 - precision_at_recall_3: 0.6014 - val_loss: 0.0028 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 10/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0020 - precision_at_recall_3: 0.1517 - val_loss: 0.0020 - val_precision_at_recall_3: 0.5000\n",
      "\u001b[1m2753/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0015 - precision_at_recall_3: 0.4196Epoch 3/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0016 - precision_at_recall_3: 0.2359 - val_loss: 0.0025 - val_precision_at_recall_3: 0.8868\n",
      "Epoch 7/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0016 - precision_at_recall_3: 0.4520 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8545\n",
      "Epoch 5/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - loss: 0.0019 - precision_at_recall_3: 0.8132 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.0019 - precision_at_recall_3: \n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0023 - precision_at_recall_3: 0.1307 - val_loss: 0.0014 - val_precision_at_recall_3: 0.4673\n",
      "Epoch 4/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0019 - precision_at_recall_3: 0.3473 - val_loss: 0.0034 - val_precision_at_recall_3: 0.8980\n",
      "Epoch 8/50\n",
      "\u001b[1m 467/3973\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0027 - precision_at_recall_3: 0.0523Epoch 1/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0024 - precision_at_recall_3: 0.0552 - val_loss: 0.0015 - val_precision_at_recall_3: 0.4220\n",
      "\u001b[1m 476/3973\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 6.7709e-04 - precision_at_recall_3: 0.7864Epoch 5/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0019 - precision_at_recall_3: 0.4220 - val_loss: 0.0016 - val_precision_at_recall_3: 0.9167\n",
      "Epoch 9/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - loss: 0.0095 - precision_at_recall_3: 0.0047 - val_loss: 0.0016 - val_precision_at_recall_3: 0.7031\n",
      "Epoch 2/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 5ms/step - loss: 0.0015 - precision_at_recall_3: 0.4819 - val_loss: 0.0017 - val_precision_at_recall_3: 0.8491\n",
      "Epoch 6/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0020 - precision_at_recall_3: 0.1707 - val_loss: 0.0014 - val_precision_at_recall_3: 0.8491\n",
      "Epoch 6/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - loss: 0.0018 - precision_at_recall_3: 0.5285 - val_loss: 0.0027 - val_precision_at_recall_3: 0.9000\n",
      "Epoch 10/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0017 - precision_at_recall_3: 0.2208 - val_loss: 7.4743e-04 - val_precision_at_recall_3: 0.9375\n",
      "\u001b[1m 268/3973\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 4.8244e-04 - precision_at_recall_3: 0.9776 Epoch 3/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 0.0017 - precision_at_recall_3: 0.4880 - val_loss: 0.0023 - val_precision_at_recall_3: 0.8545\n",
      "\u001b[1m2594/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0013 - precision_at_recall_3: 0.6905Epoch 7/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 0.0014 - precision_at_recall_3: 0.6441 - val_loss: 0.0036 - val_precision_at_recall_3: 0.9000\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/stepp - loss: 7.1521e-04 - precision_at_recall_3: 0.762\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - loss: 0.0012 - precision_at_recall_3: 0.2999 - val_loss: 6.2138e-04 - val_precision_at_recall_3: 0.9074\n",
      "Epoch 4/100\n",
      "\u001b[1m1426/3973\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0010 - precision_at_recall_3: 0.5619Epoch 1/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 0.0016 - precision_at_recall_3: 0.3285 - val_loss: 0.0015 - val_precision_at_recall_3: 0.8491\n",
      "Epoch 8/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - loss: 0.0015 - precision_at_recall_3: 0.3681 - val_loss: 0.0020 - val_precision_at_recall_3: 0.8596\n",
      "Epoch 7/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - loss: 0.0018 - precision_at_recall_3: 0.7093 - val_loss: 0.0015 - val_precision_at_recall_3: 0.8182\n",
      "\u001b[1m 804/3973\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 0.0037 - precision_at_recall_3: 0.1111Epoch 9/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0011 - precision_at_recall_3: 0.6637 - val_loss: 6.7136e-04 - val_precision_at_recall_3: 0.9074\n",
      "\u001b[1m 429/3973\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 8.8544e-04 - precision_at_recall_3: 0.8172Epoch 5/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6ms/step - loss: 0.0075 - precision_at_recall_3: 0.0067 - val_loss: 0.0013 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 2/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - loss: 0.0023 - precision_at_recall_3: 0.2825 - val_loss: 0.0026 - val_precision_at_recall_3: 0.0434\n",
      "\u001b[1m3959/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017 - precision_at_recall_3: 0.6861Epoch 8/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0017 - precision_at_recall_3: 0.6854 - val_loss: 0.0022 - val_precision_at_recall_3: 0.8868\n",
      "Epoch 10/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0012 - precision_at_recall_3: 0.7238 - val_loss: 5.6118e-04 - val_precision_at_recall_3: 0.9074\n",
      "Epoch 6/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0016 - precision_at_recall_3: 0.3460 - val_loss: 9.4077e-04 - val_precision_at_recall_3: 0.8750\n",
      "Epoch 3/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0020 - precision_at_recall_3: 0.2388 - val_loss: 0.0012 - val_precision_at_recall_3: 0.9020\n",
      "\u001b[1m2126/3973\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 0.0014 - precision_at_recall_3: 0.6534Epoch 9/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.0016 - precision_at_recall_3: 0.3864 - val_loss: 0.0018 - val_precision_at_recall_3: 0.8596\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0010 - precision_at_recall_3: 0.7024 - val_loss: 6.1639e-04 - val_precision_at_recall_3: 0.9074\n",
      "Epoch 7/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/stepp - loss: 9.3862e-04 - precision_at_recall_3: 0.848\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0013 - precision_at_recall_3: 0.7052 - val_loss: 7.4873e-04 - val_precision_at_recall_3: 0.8704\n",
      "\u001b[1m2440/3973\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0014 - precision_at_recall_3: 0.4969Epoch 4/100\n",
      "\u001b[1m 236/3973\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0021 - precision_at_recall_3: 0.1531Epoch 1/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0016 - precision_at_recall_3: 0.4753 - val_loss: 0.0017 - val_precision_at_recall_3: 0.8654\n",
      "Epoch 10/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 9.1939e-04 - precision_at_recall_3: 0.8151 - val_loss: 5.7161e-04 - val_precision_at_recall_3: 0.9184\n",
      "Epoch 8/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0011 - precision_at_recall_3: 0.6720 - val_loss: 6.8019e-04 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 5/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0163 - precision_at_recall_3: 0.0070 - val_loss: 0.0012 - val_precision_at_recall_3: 0.9200\n",
      "Epoch 2/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0016 - precision_at_recall_3: 0.6574 - val_loss: 0.0022 - val_precision_at_recall_3: 0.8421\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 7.1205e-04 - precision_at_recall_3: 0.7263 - val_loss: 6.4653e-04 - val_precision_at_recall_3: 0.9600\n",
      "Epoch 9/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0018 - precision_at_recall_3: 0.44634   \n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 8.5647e-04 - precision_at_recall_3: 0.6590 - val_loss: 7.0267e-04 - val_precision_at_recall_3: 0.8596\n",
      "Epoch 6/100\n",
      "\u001b[1m1573/3973\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0011 - precision_at_recall_3: 0.4992Epoch 1/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0016 - precision_at_recall_3: 0.5082 - val_loss: 8.7567e-04 - val_precision_at_recall_3: 0.8750\n",
      "Epoch 3/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 0.0010 - precision_at_recall_3: 0.6384 - val_loss: 7.8455e-04 - val_precision_at_recall_3: 0.9184\n",
      "\u001b[1m1760/3973\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0175 - precision_at_recall_3: 0.0021Epoch 10/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - loss: 0.0103 - precision_at_recall_3: 0.0048 - val_loss: 0.0014 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 2/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0010 - precision_at_recall_3: 0.7603 - val_loss: 9.8211e-04 - val_precision_at_recall_3: 0.9020\n",
      "Epoch 4/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 8.0605e-04 - precision_at_recall_3: 0.7833 - val_loss: 5.8293e-04 - val_precision_at_recall_3: 0.9375\n",
      "\u001b[1m 283/3973\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 7.7108e-04 - precision_at_recall_3: 0.4337Epoch 11/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 5ms/step - loss: 7.5583e-04 - precision_at_recall_3: 0.7793 - val_loss: 7.2893e-04 - val_precision_at_recall_3: 0.8500\n",
      "Epoch 7/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 9.6406e-04 - precision_at_recall_3: 0.7114 - val_loss: 0.0011 - val_precision_at_recall_3: 0.9020\n",
      "Epoch 5/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 5ms/step - loss: 0.0016 - precision_at_recall_3: 0.4015 - val_loss: 0.0013 - val_precision_at_recall_3: 0.8571\n",
      "\u001b[1m1341/3973\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 6.6456e-04 - precision_at_recall_3: 0.8314Epoch 3/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 8.0669e-04 - precision_at_recall_3: 0.6909 - val_loss: 6.8923e-04 - val_precision_at_recall_3: 1.0000\n",
      "\u001b[1m 283/3973\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 0.0011 - precision_at_recall_3: 0.7143Epoch 12/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 7.4989e-04 - precision_at_recall_3: 0.8480 - val_loss: 8.5652e-04 - val_precision_at_recall_3: 0.9020\n",
      "Epoch 8/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0010 - precision_at_recall_3: 0.7125 - val_loss: 0.0011 - val_precision_at_recall_3: 0.8571\n",
      "\u001b[1m1299/3973\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 0.0010 - precision_at_recall_3: 0.7964Epoch 4/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 7.7984e-04 - precision_at_recall_3: 0.8093 - val_loss: 8.5064e-04 - val_precision_at_recall_3: 0.9362\n",
      "Epoch 6/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 8.6580e-04 - precision_at_recall_3: 0.7996 - val_loss: 7.2280e-04 - val_precision_at_recall_3: 0.8909\n",
      "Epoch 13/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 8.8658e-04 - precision_at_recall_3: 0.8366 - val_loss: 7.6651e-04 - val_precision_at_recall_3: 0.8727\n",
      "Epoch 9/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 9.1053e-04 - precision_at_recall_3: 0.7920 - val_loss: 9.6794e-04 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 5/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 6.3304e-04 - precision_at_recall_3: 0.8562 - val_loss: 5.4718e-04 - val_precision_at_recall_3: 0.9574\n",
      "Epoch 14/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 7.2156e-04 - precision_at_recall_3: 0.8457 - val_loss: 8.7432e-04 - val_precision_at_recall_3: 0.8545\n",
      "Epoch 10/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 5.2399e-04 - precision_at_recall_3: 0.8555 - val_loss: 5.6673e-04 - val_precision_at_recall_3: 0.9787\n",
      "Epoch 15/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 5ms/step - loss: 8.9144e-04 - precision_at_recall_3: 0.6653 - val_loss: 0.0011 - val_precision_at_recall_3: 0.9184\n",
      "Epoch 7/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 8.7650e-04 - precision_at_recall_3: 0.7343 - val_loss: 8.9764e-04 - val_precision_at_recall_3: 0.8654\n",
      "Epoch 6/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 7.4129e-04 - precision_at_recall_3: 0.8197 - val_loss: 0.0010 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 7.1576e-04 - precision_at_recall_3: 0.705\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 6.0868e-04 - precision_at_recall_3: 0.8623 - val_loss: 6.1095e-04 - val_precision_at_recall_3: 0.9783\n",
      "Epoch 16/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 7.4603e-04 - precision_at_recall_3: 0.7193 - val_loss: 9.6712e-04 - val_precision_at_recall_3: 0.9038\n",
      "Epoch 8/100\n",
      "\u001b[1m1403/3973\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 6.5182e-04 - precision_at_recall_3: 0.7919Epoch 1/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 7.0731e-04 - precision_at_recall_3: 0.8200 - val_loss: 8.5552e-04 - val_precision_at_recall_3: 0.9362\n",
      "Epoch 9/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 6.7016e-04 - precision_at_recall_3: 0.8697 - val_loss: 6.9061e-04 - val_precision_at_recall_3: 0.9574\n",
      "Epoch 17/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5ms/step - loss: 8.7204e-04 - precision_at_recall_3: 0.8143 - val_loss: 9.8219e-04 - val_precision_at_recall_3: 0.8571\n",
      "\u001b[1m3273/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 7.9168e-04 - precision_at_recall_3: 0.7745Epoch 7/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6ms/step - loss: 0.0089 - precision_at_recall_3: 0.0055 - val_loss: 9.5995e-04 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 2/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 7.8695e-04 - precision_at_recall_3: 0.7812 - val_loss: 0.0010 - val_precision_at_recall_3: 0.9362\n",
      "Epoch 10/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 6.7435e-04 - precision_at_recall_3: 0.8336 - val_loss: 6.1114e-04 - val_precision_at_recall_3: 0.9787\n",
      "Epoch 18/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0012 - precision_at_recall_3: 0.6413 - val_loss: 0.0010 - val_precision_at_recall_3: 0.8704\n",
      "\u001b[1m2919/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 8.9498e-04 - precision_at_recall_3: 0.6861Epoch 8/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 7.3954e-04 - precision_at_recall_3: 0.8497 - val_loss: 9.7226e-04 - val_precision_at_recall_3: 0.9184\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 8.3608e-04 - precision_at_recall_3: 0.7288 - val_loss: 6.5744e-04 - val_precision_at_recall_3: 0.9783\n",
      "\u001b[1m 492/3973\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0018 - precision_at_recall_3: 0.3150Epoch 19/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/stepp - loss: 2.4529e-04 - precision_at_recall_3: 0.971\n",
      "\u001b[1m3314/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0017 - precision_at_recall_3: 0.1808Epoch 1/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 8.6854e-04 - precision_at_recall_3: 0.7731 - val_loss: 9.6550e-04 - val_precision_at_recall_3: 0.8750\n",
      "\u001b[1m2873/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 3.7737e-04 - precision_at_recall_3: 0.9377Epoch 9/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 4ms/step - loss: 0.0016 - precision_at_recall_3: 0.2022 - val_loss: 8.8766e-04 - val_precision_at_recall_3: 0.8654\n",
      "Epoch 3/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 4.4610e-04 - precision_at_recall_3: 0.9135 - val_loss: 5.6032e-04 - val_precision_at_recall_3: 0.9792\n",
      "Epoch 20/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 9.5628e-04 - precision_at_recall_3: 0.7701 - val_loss: 0.0010 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 10/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - loss: 0.0012 - precision_at_recall_3: 0.6052 - val_loss: 9.4277e-04 - val_precision_at_recall_3: 0.8679\n",
      "Epoch 4/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 4.8732e-04 - precision_at_recall_3: 0.8912 - val_loss: 7.1615e-04 - val_precision_at_recall_3: 0.9184\n",
      "Epoch 21/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0065 - precision_at_recall_3: 0.0034 - val_loss: 9.4673e-04 - val_precision_at_recall_3: 0.8750\n",
      "Epoch 2/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - loss: 7.6029e-04 - precision_at_recall_3: 0.7746 - val_loss: 9.8481e-04 - val_precision_at_recall_3: 0.8654\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 9.5711e-04 - precision_at_recall_3: 0.7516 - val_loss: 9.6041e-04 - val_precision_at_recall_3: 0.8654\n",
      "Epoch 5/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.0018 - precision_at_recall_3: 0.360.791\n",
      "\u001b[1m1337/3973\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - loss: 0.0013 - precision_at_recall_3: 0.6330 Epoch 1/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.0018 - precision_at_recall_3: 0.3619 - val_loss: 7.7590e-04 - val_precision_at_recall_3: 0.8889\n",
      "\u001b[1m1413/3973\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - loss: 0.0013 - precision_at_recall_3: 0.6343Epoch 3/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 7.0147e-04 - precision_at_recall_3: 0.7995 - val_loss: 6.4600e-04 - val_precision_at_recall_3: 0.9800\n",
      "Epoch 22/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.0012 - precision_at_recall_3: 0.5876 - val_loss: 8.9782e-04 - val_precision_at_recall_3: 0.8182\n",
      "Epoch 6/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0015 - precision_at_recall_3: 0.2826 - val_loss: 7.5190e-04 - val_precision_at_recall_3: 0.9057\n",
      "Epoch 4/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 5.5443e-04 - precision_at_recall_3: 0.8980 - val_loss: 7.4839e-04 - val_precision_at_recall_3: 0.9796\n",
      "Epoch 23/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0043 - precision_at_recall_3: 0.0101 - val_loss: 9.3941e-04 - val_precision_at_recall_3: 0.8448\n",
      "Epoch 2/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 7.6555e-04 - precision_at_recall_3: 0.7473 - val_loss: 9.7059e-04 - val_precision_at_recall_3: 0.8679\n",
      "Epoch 7/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0014 - precision_at_recall_3: 0.3020 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8868\n",
      "Epoch 5/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0015 - precision_at_recall_3: 0.3780 - val_loss: 9.4777e-04 - val_precision_at_recall_3: 0.8545\n",
      "Epoch 3/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0016 - precision_at_recall_3: 0.3888 - val_loss: 0.0011 - val_precision_at_recall_3: 0.8889\n",
      "Epoch 6/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0010 - precision_at_recall_3: 0.7955 - val_loss: 8.2818e-04 - val_precision_at_recall_3: 0.8824\n",
      "Epoch 8/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0015 - precision_at_recall_3: 0.2360 - val_loss: 0.0010 - val_precision_at_recall_3: 0.8868\n",
      "Epoch 4/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - loss: 5.5417e-04 - precision_at_recall_3: 0.9118 - val_loss: 7.6641e-04 - val_precision_at_recall_3: 0.9375\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.0017 - precision_at_recall_3: 0.34\n",
      "\u001b[1m2960/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0015 - precision_at_recall_3: 0.5140Epoch 1/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0016 - precision_at_recall_3: 0.3800 - val_loss: 7.8981e-04 - val_precision_at_recall_3: 0.8909\n",
      "Epoch 7/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 0.0015 - precision_at_recall_3: 0.4712 - val_loss: 0.0013 - val_precision_at_recall_3: 0.7931\n",
      "Epoch 5/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0016 - precision_at_recall_3: 0.6325 - val_loss: 9.8761e-04 - val_precision_at_recall_3: 0.8846\n",
      "Epoch 8/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0012 - precision_at_recall_3: 0.4592 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 6/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 6ms/step - loss: 0.0059 - precision_at_recall_3: 0.0043 - val_loss: 0.0015 - val_precision_at_recall_3: 0.9000\n",
      "Epoch 2/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 6ms/step - loss: 8.0763e-04 - precision_at_recall_3: 0.8039 - val_loss: 8.4878e-04 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 9/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0012 - precision_at_recall_3: 0.2804 - val_loss: 7.5071e-04 - val_precision_at_recall_3: 0.9020\n",
      "Epoch 9/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0013 - precision_at_recall_3: 0.5781 - val_loss: 0.0010 - val_precision_at_recall_3: 0.8750\n",
      "Epoch 7/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0014 - precision_at_recall_3: 0.3316 - val_loss: 0.0013 - val_precision_at_recall_3: 0.9000\n",
      "Epoch 3/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 9.2241e-04 - precision_at_recall_3: 0.7188 - val_loss: 8.7299e-04 - val_precision_at_recall_3: 0.8846\n",
      "Epoch 10/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - loss: 9.5392e-04 - precision_at_recall_3: 0.7091 - val_loss: 7.9734e-04 - val_precision_at_recall_3: 0.8909\n",
      "Epoch 10/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0016 - precision_at_recall_3: 0.4279 - val_loss: 9.4750e-04 - val_precision_at_recall_3: 0.8846\n",
      "Epoch 4/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 7.6709e-04 - precision_at_recall_3: 0.7127 - val_loss: 0.0010 - val_precision_at_recall_3: 0.8846\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/stepp - loss: 0.0018 - precision_at_recall_3: 0.35.89\n",
      "\u001b[1m2503/3973\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0015 - precision_at_recall_3: 0.5622Epoch 1/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 8.9890e-04 - precision_at_recall_3: 0.8702 - val_loss: 8.8339e-04 - val_precision_at_recall_3: 0.8868\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0014 - precision_at_recall_3: 0.4879 - val_loss: 0.0014 - val_precision_at_recall_3: 0.9167\n",
      "Epoch 5/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - loss: 0.0014 - precision_at_recall_3: 0.6197 - val_loss: 0.0011 - val_precision_at_recall_3: 0.8868\n",
      "Epoch 8/100\n",
      "\u001b[1m 489/3973\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0153 - precision_at_recall_3: 0.0015Epoch 1/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0054 - precision_at_recall_3: 0.0125 - val_loss: 0.0017 - val_precision_at_recall_3: 0.8571\n",
      "\u001b[1m2561/3973\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0081 - precision_at_recall_3: 0.0034Epoch 2/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0018 - precision_at_recall_3: 0.3093 - val_loss: 0.0011 - val_precision_at_recall_3: 0.9184\n",
      "Epoch 6/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0011 - precision_at_recall_3: 0.7078 - val_loss: 7.9674e-04 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 9/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0063 - precision_at_recall_3: 0.0067 - val_loss: 0.0013 - val_precision_at_recall_3: 0.8519\n",
      "\u001b[1m2301/3973\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.0015 - precision_at_recall_3: 0.4102Epoch 2/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0013 - precision_at_recall_3: 0.4218 - val_loss: 0.0011 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 3/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0015 - precision_at_recall_3: 0.4794 - val_loss: 0.0014 - val_precision_at_recall_3: 0.9167\n",
      "Epoch 7/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - loss: 0.0018 - precision_at_recall_3: 0.1015 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8393\n",
      "Epoch 3/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.0012 - precision_at_recall_3: 0.7532 - val_loss: 0.0015 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 4/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0015 - precision_at_recall_3: 0.6011 - val_loss: 0.0011 - val_precision_at_recall_3: 0.8800\n",
      "Epoch 8/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5ms/step - loss: 9.8692e-04 - precision_at_recall_3: 0.7993 - val_loss: 9.2194e-04 - val_precision_at_recall_3: 0.8727\n",
      "Epoch 10/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.0016 - precision_at_recall_3: 0.4764 - val_loss: 0.0018 - val_precision_at_recall_3: 0.3561\n",
      "Epoch 4/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0015 - precision_at_recall_3: 0.4837 - val_loss: 0.0014 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 5/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0012 - precision_at_recall_3: 0.6795 - val_loss: 0.0013 - val_precision_at_recall_3: 0.9000\n",
      "Epoch 9/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.0013 - precision_at_recall_3: 0.6234 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8727\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.0016 - precision_at_recall_3: 0.557\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.0013 - precision_at_recall_3: 0.6270 - val_loss: 0.0010 - val_precision_at_recall_3: 0.8333\n",
      "Epoch 5/100\n",
      "\u001b[1m1821/3973\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 0.0016 - precision_at_recall_3: 0.3217Epoch 1/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0019 - precision_at_recall_3: 0.2025 - val_loss: 0.0014 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 6/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0014 - precision_at_recall_3: 0.6399 - val_loss: 0.0013 - val_precision_at_recall_3: 0.8868\n",
      "Epoch 10/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0015 - precision_at_recall_3: 0.4588 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8491\n",
      "Epoch 6/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.0011 - precision_at_recall_3: 0.7215 - val_loss: 0.0011 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 7/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 0.0011 - precision_at_recall_3: 0.7470 - val_loss: 0.0141 - val_precision_at_recall_3: 0.5432\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0048 - precision_at_recall_3: 0.0049 - val_loss: 9.5360e-04 - val_precision_at_recall_3: 0.8750\n",
      "Epoch 2/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0015 - precision_at_recall_3: 0.5199 - val_loss: 0.0012 - val_precision_at_recall_3: 0.9000\n",
      "Epoch 7/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0010 - precision_at_recall_3: 0.5331 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 8/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0020 - precision_at_recall_3: 0.3631 - val_loss: 0.0010 - val_precision_at_recall_3: 0.8868\n",
      "\u001b[1m 673/3973\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 6.6373e-04 - precision_at_recall_3: 0.8856Epoch 3/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0014 - precision_at_recall_3: 0.3993 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8824\n",
      "Epoch 8/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/stepp - loss: 0.0022 - precision_at_recall_3: 0.21.78\n",
      "\u001b[1m2110/3973\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0015 - precision_at_recall_3: 0.3114Epoch 1/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0011 - precision_at_recall_3: 0.7106 - val_loss: 8.6438e-04 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 9/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0022 - precision_at_recall_3: 0.1412 - val_loss: 8.0585e-04 - val_precision_at_recall_3: 0.9074\n",
      "Epoch 4/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0014 - precision_at_recall_3: 0.3980 - val_loss: 0.0011 - val_precision_at_recall_3: 0.8679\n",
      "Epoch 9/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0014 - precision_at_recall_3: 0.5269 - val_loss: 0.0015 - val_precision_at_recall_3: 0.8545\n",
      "Epoch 10/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0019 - precision_at_recall_3: 0.3673 - val_loss: 0.0013 - val_precision_at_recall_3: 0.6479\n",
      "Epoch 5/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0047 - precision_at_recall_3: 0.0079 - val_loss: 0.0011 - val_precision_at_recall_3: 0.8679\n",
      "Epoch 2/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0011 - precision_at_recall_3: 0.6992 - val_loss: 0.0024 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0015 - precision_at_recall_3: 0.3764 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 3/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/stepp - loss: 0.0013 - precision_at_recall_3: 0.82\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 6ms/step - loss: 0.0021 - precision_at_recall_3: 0.1318 - val_loss: 9.7202e-04 - val_precision_at_recall_3: 0.8909\n",
      "Epoch 6/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 5ms/step - loss: 0.0017 - precision_at_recall_3: 0.2651 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8545\n",
      "Epoch 10/100\n",
      "\u001b[1m 223/3973\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0017 - precision_at_recall_3: 0.5697Epoch 1/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 0.0014 - precision_at_recall_3: 0.5426 - val_loss: 0.0011 - val_precision_at_recall_3: 0.8596\n",
      "Epoch 4/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0015 - precision_at_recall_3: 0.4793 - val_loss: 0.0013 - val_precision_at_recall_3: 0.8545\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5ms/step - loss: 0.0062 - precision_at_recall_3: 0.0128 - val_loss: 0.0020 - val_precision_at_recall_3: 0.8980\n",
      "\u001b[1m2677/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0016 - precision_at_recall_3: 0.3609Epoch 2/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0016 - precision_at_recall_3: 0.368\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0020 - precision_at_recall_3: 0.3478 - val_loss: 0.0013 - val_precision_at_recall_3: 0.8727\n",
      "Epoch 5/100\n",
      "\u001b[1m 945/3973\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.0014 - precision_at_recall_3: 0.4259Epoch 1/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - loss: 0.0016 - precision_at_recall_3: 0.3312 - val_loss: 0.0010 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 7/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0025 - precision_at_recall_3: 0.2400 - val_loss: 0.0014 - val_precision_at_recall_3: 0.8824\n",
      "Epoch 3/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.0015 - precision_at_recall_3: 0.5320 - val_loss: 0.0019 - val_precision_at_recall_3: 0.7931\n",
      "\u001b[1m 725/3973\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 0.0016 - precision_at_recall_3: 0.1079Epoch 6/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0013 - precision_at_recall_3: 0.4559 - val_loss: 9.3553e-04 - val_precision_at_recall_3: 0.9000\n",
      "Epoch 8/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0064 - precision_at_recall_3: 0.0105 - val_loss: 0.0015 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 2/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0019 - precision_at_recall_3: 0.1632 - val_loss: 0.0016 - val_precision_at_recall_3: 0.8868\n",
      "Epoch 4/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0015 - precision_at_recall_3: 0.7018 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8421\n",
      "Epoch 7/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0020 - precision_at_recall_3: 0.5101 - val_loss: 8.1672e-04 - val_precision_at_recall_3: 0.8909\n",
      "Epoch 9/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0018 - precision_at_recall_3: 0.3029 - val_loss: 0.0013 - val_precision_at_recall_3: 0.8679\n",
      "Epoch 3/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0015 - precision_at_recall_3: 0.4344 - val_loss: 0.0019 - val_precision_at_recall_3: 0.9167\n",
      "\u001b[1m2466/3973\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0012 - precision_at_recall_3: 0.5912Epoch 5/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0013 - precision_at_recall_3: 0.5964 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8889\n",
      "Epoch 10/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0019 - precision_at_recall_3: 0.5876 - val_loss: 0.0011 - val_precision_at_recall_3: 0.8679\n",
      "\u001b[1m 121/3973\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 1.4956e-04 - precision_at_recall_3: 0.9917Epoch 4/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - loss: 0.0024 - precision_at_recall_3: 0.1861 - val_loss: 0.0015 - val_precision_at_recall_3: 0.8889\n",
      "Epoch 6/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5ms/step - loss: 0.0016 - precision_at_recall_3: 0.2757 - val_loss: 0.0013 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 8/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 5ms/step - loss: 0.0014 - precision_at_recall_3: 0.5300 - val_loss: 0.0016 - val_precision_at_recall_3: 0.8889\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0014 - precision_at_recall_3: 0.5619 - val_loss: 0.0017 - val_precision_at_recall_3: 0.8727\n",
      "Epoch 5/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 9.7034e-04 - precision_at_recall_3: 0.613\n",
      "\u001b[1m3778/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0010 - precision_at_recall_3: 0.5841Epoch 1/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - loss: 0.0013 - precision_at_recall_3: 0.5447 - val_loss: 0.0056 - val_precision_at_recall_3: 0.7857\n",
      "Epoch 7/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0010 - precision_at_recall_3: 0.5873 - val_loss: 0.0011 - val_precision_at_recall_3: 0.8846\n",
      "Epoch 9/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0019 - precision_at_recall_3: 0.3254 - val_loss: 0.0015 - val_precision_at_recall_3: 0.9167\n",
      "Epoch 8/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - loss: 0.0070 - precision_at_recall_3: 0.0055 - val_loss: 0.0010 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 2/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5ms/step - loss: 0.0014 - precision_at_recall_3: 0.4066 - val_loss: 0.0013 - val_precision_at_recall_3: 0.8679\n",
      "Epoch 10/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 6ms/step - loss: 0.0014 - precision_at_recall_3: 0.4881 - val_loss: 0.0014 - val_precision_at_recall_3: 0.7143\n",
      "Epoch 6/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0018 - precision_at_recall_3: 0.3098 - val_loss: 0.0025 - val_precision_at_recall_3: 0.9167\n",
      "Epoch 9/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 0.0021 - precision_at_recall_3: 0.2891 - val_loss: 0.0014 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 3/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0015 - precision_at_recall_3: 0.5151 - val_loss: 0.0034 - val_precision_at_recall_3: 0.8980\n",
      "Epoch 10/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0017 - precision_at_recall_3: 0.1974 - val_loss: 0.0019 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 4/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5ms/step - loss: 0.0018 - precision_at_recall_3: 0.4780 - val_loss: 0.0013 - val_precision_at_recall_3: 0.8596\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.0016 - precision_at_recall_3: 0.6169 - val_loss: 0.0021 - val_precision_at_recall_3: 0.9167\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0016 - precision_at_recall\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 5ms/step - loss: 0.0014 - precision_at_recall_3: 0.5464 - val_loss: 0.0022 - val_precision_at_recall_3: 0.8491\n",
      "Epoch 7/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.0016 - precision_at_recall_3: 0.3532 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8679\n",
      "Epoch 5/100\n",
      "\u001b[1m 818/3973\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 0.0016 - precision_at_recall_3: 0.4921Epoch 1/50\n",
      "\u001b[1m 763/3973\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 0.0015 - precision_at_recall_3: 0.1374Epoch 1/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0017 - precision_at_recall_3: 0.2137 - val_loss: 0.0014 - val_precision_at_recall_3: 0.7931\n",
      "\u001b[1m2231/3973\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0059 - precision_at_recall_3: 0.0124Epoch 6/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.0017 - precision_at_recall_3: 0.5253 - val_loss: 0.0014 - val_precision_at_recall_3: 0.8654\n",
      "Epoch 8/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0045 - precision_at_recall_3: 0.0256 - val_loss: 0.0010 - val_precision_at_recall_3: 0.8750\n",
      "\u001b[1m2829/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0016 - precision_at_recall_3: 0.4235Epoch 2/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0062 - precision_at_recall_3: 0.0118 - val_loss: 0.0017 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 2/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.0017 - precision_at_recall_3: 0.3894 - val_loss: 9.8730e-04 - val_precision_at_recall_3: 0.8393\n",
      "Epoch 7/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0013 - precision_at_recall_3: 0.6475 - val_loss: 0.0014 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 9/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0016 - precision_at_recall_3: 0.3871 - val_loss: 9.5456e-04 - val_precision_at_recall_3: 0.8909\n",
      "Epoch 3/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0016 - precision_at_recall_3: 0.3083 - val_loss: 0.0015 - val_precision_at_recall_3: 0.8491\n",
      "Epoch 8/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0014 - precision_at_recall_3: 0.5876 - val_loss: 0.0013 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 10/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - loss: 0.0013 - precision_at_recall_3: 0.5294 - val_loss: 0.0013 - val_precision_at_recall_3: 0.9038\n",
      "Epoch 4/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 6ms/step - loss: 0.0015 - precision_at_recall_3: 0.4226 - val_loss: 0.0022 - val_precision_at_recall_3: 0.8596\n",
      "Epoch 3/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - loss: 0.0015 - precision_at_recall_3: 0.2680 - val_loss: 0.0018 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 9/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 0.0015 - precision_at_recall_3: 0.6882 - val_loss: 0.0011 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0014 - precision_at_recall_3: 0.6419 - val_loss: 9.6300e-04 - val_precision_at_recall_3: 0.8889\n",
      "Epoch 5/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0013 - precision_at_recall_3: 0.4484 - val_loss: 0.0027 - val_precision_at_recall_3: 0.6818\n",
      "Epoch 10/100\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 0.0014 - precision_at_recall_3: 0.4275 - val_loss: 8.3565e-04 - val_precision_at_recall_3: 0.9020\n",
      "Epoch 6/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.0021 - precision_at_recall_3: 0.14 0.555\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - loss: 0.0014 - precision_at_recall_3: 0.4800 - val_loss: 0.0024 - val_precision_at_recall_3: 0.7627\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m2264/3973\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 8.7845e-04 - precision_at_recall_3: 0.7371Epoch 1/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - loss: 0.0020 - precision_at_recall_3: 0.1465 - val_loss: 0.0014 - val_precision_at_recall_3: 0.8545\n",
      "Epoch 4/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0011 - precision_at_recall_3: 0.8201\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0011 - precision_at_recall_3: 0.5968 - val_loss: 0.0013 - val_precision_at_recall_3: 0.7258\n",
      "Epoch 7/50\n",
      "\u001b[1m 841/3973\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 0.0019 - precision_at_recall_3: 0.1491Epoch 1/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0012 - precision_at_recall_3: 0.7937 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8679\n",
      "Epoch 5/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0044 - precision_at_recall_3: 0.0489 - val_loss: 0.0011 - val_precision_at_recall_3: 0.8980\n",
      "Epoch 2/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0017 - precision_at_recall_3: 0.3034 - val_loss: 0.0011 - val_precision_at_recall_3: 0.8909\n",
      "Epoch 8/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 0.0012 - precision_at_recall_3: 0.7170 - val_loss: 0.0010 - val_precision_at_recall_3: 0.8750\n",
      "\u001b[1m3491/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0013 - precision_at_recall_3: 0.7204Epoch 6/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - loss: 0.0032 - precision_at_recall_3: 0.0644 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 2/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 0.0013 - precision_at_recall_3: 0.6856 - val_loss: 0.0013 - val_precision_at_recall_3: 0.7458\n",
      "Epoch 3/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 6ms/step - loss: 0.0013 - precision_at_recall_3: 0.5861 - val_loss: 0.0011 - val_precision_at_recall_3: 0.8036\n",
      "Epoch 9/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0012 - precision_at_recall_3: 0.4167 - val_loss: 0.0014 - val_precision_at_recall_3: 0.8750\n",
      "Epoch 7/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0017 - precision_at_recall_3: 0.2665 - val_loss: 0.0013 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 3/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0016 - precision_at_recall_3: 0.4184 - val_loss: 0.0013 - val_precision_at_recall_3: 0.9020\n",
      "Epoch 4/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 7.9970e-04 - precision_at_recall_3: 0.7465 - val_loss: 9.8199e-04 - val_precision_at_recall_3: 0.8727\n",
      "Epoch 10/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0014 - precision_at_recall_3: 0.7298 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8750\n",
      "Epoch 8/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0016 - precision_at_recall_3: 0.6218 - val_loss: 0.0027 - val_precision_at_recall_3: 0.7258\n",
      "Epoch 5/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0012 - precision_at_recall_3: 0.5005 - val_loss: 7.6556e-04 - val_precision_at_recall_3: 0.9057\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.0012 - precision_at_recall_3: 0.671\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - loss: 0.0010 - precision_at_recall_3: 0.6845 - val_loss: 0.0017 - val_precision_at_recall_3: 0.8727\n",
      "\u001b[1m3743/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - precision_at_recall_3: 0.6709Epoch 9/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 5ms/step - loss: 0.0016 - precision_at_recall_3: 0.3512 - val_loss: 0.0017 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 4/50\n",
      "\u001b[1m  26/3973\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 6ms/step - loss: 6.1540e-05 - precision_at_recall_3: 0.8077Epoch 1/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0012 - precision_at_recall_3: 0.6688 - val_loss: 0.0034 - val_precision_at_recall_3: 0.8302\n",
      "Epoch 6/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.0015 - precision_at_recall_3: 0.4856 - val_loss: 0.0026 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 5/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - loss: 9.0389e-04 - precision_at_recall_3: 0.7640 - val_loss: 0.0025 - val_precision_at_recall_3: 0.8421\n",
      "Epoch 10/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - loss: 0.0016 - precision_at_recall_3: 0.6297 - val_loss: 0.0023 - val_precision_at_recall_3: 0.9000\n",
      "\u001b[1m1007/3973\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - loss: 0.0013 - precision_at_recall_3: 0.4121Epoch 7/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0053 - precision_at_recall_3: 0.0128 - val_loss: 0.0022 - val_precision_at_recall_3: 0.5696\n",
      "\u001b[1m1135/3973\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 0.0015 - precision_at_recall_3: 0.5970Epoch 2/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0022 - precision_at_recall_3: 0.4294 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8519\n",
      "\u001b[1m3409/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0017 - precision_at_recall_3: 0.5418Epoch 6/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - loss: 0.0012 - precision_at_recall_3: 0.4972 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8727\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.0017 - precision_at_recall_3: 0.5419 - val_loss: 0.0017 - val_precision_at_recall_3: 0.9200\n",
      "Epoch 8/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0019 - precision_at_recall_3: 0.0683 - val_loss: 0.0017 - val_precision_at_recall_3: 0.8679\n",
      "\u001b[1m3463/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0014 - precision_at_recall_3: 0.5174Epoch 3/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0013 - precision_at_recall_3: 0.5413 - val_loss: 0.0016 - val_precision_at_recall_3: 0.8824\n",
      "Epoch 7/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 0.0015 - precision_at_recall_3: 0.5490 - val_loss: 0.0028 - val_precision_at_recall_3: 0.9184\n",
      "Epoch 9/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/stepp - loss: 7.8220e-04 - precision_at_recall_3: 0.749\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0018 - precision_at_recall_3: 0.2861 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8679\n",
      "Epoch 4/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0018 - precision_at_recall_3: 0.5277 - val_loss: 0.0020 - val_precision_at_recall_3: 0.8448\n",
      "Epoch 8/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0013 - precision_at_recall_3: 0.6202 - val_loss: 0.0030 - val_precision_at_recall_3: 0.9184\n",
      "Epoch 10/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0013 - precision_at_recall_3: 0.5413 - val_loss: 0.0012 - val_precision_at_recall_3: 0.8846\n",
      "\u001b[1m2765/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 8.8929e-04 - precision_at_recall_3: 0.6355Epoch 5/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0016 - precision_at_recall_3: 0.4546 - val_loss: 0.0014 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 9/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 9.8923e-04 - precision_at_recall_3: 0.6330 - val_loss: 0.0038 - val_precision_at_recall_3: 0.9000\n",
      "\u001b[1m1984/3973\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0015 - precision_at_recall_3: 0.3311Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.0013 - precision_at_recall_3: 0.653\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 0.0016 - precision_at_recall_3: 0.3540 - val_loss: 0.0018 - val_precision_at_recall_3: 0.8846\n",
      "Epoch 6/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0013 - precision_at_recall_3: 0.6724 - val_loss: 0.0015 - val_precision_at_recall_3: 0.8679\n",
      "Epoch 10/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0014 - precision_at_recall_3: 0.6286 - val_loss: 0.0014 - val_precision_at_recall_3: 0.8824\n",
      "Epoch 7/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0011 - precision_at_recall_3: 0.6408 - val_loss: 0.0015 - val_precision_at_recall_3: 0.8846\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0013 - precision_at_recall_3: 0.549\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0014 - precision_at_recall_3: 0.5352 - val_loss: 0.0014 - val_precision_at_recall_3: 0.7667\n",
      "Epoch 8/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0013 - precision_at_recall_3: 0.5090 - val_loss: 0.0022 - val_precision_at_recall_3: 0.8824\n",
      "Epoch 9/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 8.6980e-04 - precision_at_recall_3: 0.7178 - val_loss: 0.0028 - val_precision_at_recall_3: 0.9184\n",
      "Epoch 10/50\n",
      "\u001b[1m3973/3973\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0014 - precision_at_recall_3: 0.4676 - val_loss: 0.0020 - val_precision_at_recall_3: 0.8704\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Epoch 1/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 0.0058 - precision_at_recall_3: 0.0249 - val_loss: 9.4000e-04 - val_precision_at_recall_3: 0.8636\n",
      "Epoch 2/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0014 - precision_at_recall_3: 0.4484 - val_loss: 8.6632e-04 - val_precision_at_recall_3: 0.8571\n",
      "Epoch 3/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 9.3628e-04 - precision_at_recall_3: 0.6228 - val_loss: 0.0011 - val_precision_at_recall_3: 0.8806\n",
      "Epoch 4/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0012 - precision_at_recall_3: 0.6765 - val_loss: 7.7636e-04 - val_precision_at_recall_3: 0.8769\n",
      "Epoch 5/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 9.2584e-04 - precision_at_recall_3: 0.8453 - val_loss: 7.8526e-04 - val_precision_at_recall_3: 0.8806\n",
      "Epoch 6/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 9.2274e-04 - precision_at_recall_3: 0.7757 - val_loss: 8.0848e-04 - val_precision_at_recall_3: 0.8906\n",
      "Epoch 7/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 9.1588e-04 - precision_at_recall_3: 0.8210 - val_loss: 8.7959e-04 - val_precision_at_recall_3: 0.8788\n",
      "Epoch 8/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 9.4404e-04 - precision_at_recall_3: 0.8058 - val_loss: 8.9956e-04 - val_precision_at_recall_3: 0.8788\n",
      "Epoch 9/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0010 - precision_at_recall_3: 0.8102 - val_loss: 8.9370e-04 - val_precision_at_recall_3: 0.8676\n",
      "Epoch 10/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 7.0519e-04 - precision_at_recall_3: 0.7886 - val_loss: 7.1498e-04 - val_precision_at_recall_3: 0.8806\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Best hyperparameters: {'mlp__batch_size': 32, 'mlp__epochs': 100, 'mlp__model__dropout_rate': 0.37840920206250117, 'mlp__model__learning_rate': 0.0008773260590279343, 'mlp__model__neurons': 83}\n",
      "Epoch 1/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 0.0093 - precision_at_recall_3: 0.0417 - val_loss: 8.9745e-04 - val_precision_at_recall_3: 0.8923\n",
      "Epoch 2/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0015 - precision_at_recall_3: 0.4594 - val_loss: 8.2873e-04 - val_precision_at_recall_3: 0.8806\n",
      "Epoch 3/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0012 - precision_at_recall_3: 0.5270 - val_loss: 8.8920e-04 - val_precision_at_recall_3: 0.8824\n",
      "Epoch 4/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0011 - precision_at_recall_3: 0.5624 - val_loss: 8.7670e-04 - val_precision_at_recall_3: 0.8696\n",
      "Epoch 5/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 9.7359e-04 - precision_at_recall_3: 0.7638 - val_loss: 8.9967e-04 - val_precision_at_recall_3: 0.8806\n",
      "Epoch 6/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 9.1789e-04 - precision_at_recall_3: 0.6760 - val_loss: 8.0957e-04 - val_precision_at_recall_3: 0.8750\n",
      "Epoch 7/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 7.3206e-04 - precision_at_recall_3: 0.8170 - val_loss: 8.7303e-04 - val_precision_at_recall_3: 0.8788\n",
      "Epoch 8/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 7.6618e-04 - precision_at_recall_3: 0.7615 - val_loss: 7.3966e-04 - val_precision_at_recall_3: 0.8806\n",
      "Epoch 9/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 7.9788e-04 - precision_at_recall_3: 0.8021 - val_loss: 7.6022e-04 - val_precision_at_recall_3: 0.8889\n",
      "Epoch 10/100\n",
      "\u001b[1m4966/4966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 8.6183e-04 - precision_at_recall_3: 0.8360 - val_loss: 8.5442e-04 - val_precision_at_recall_3: 0.8806\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-12 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-12 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-12 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-12 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-12 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-12 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-12 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-12 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-12 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(force_int_remainder_cols=False,\n",
       "                                   remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;drop_cols&#x27;, &#x27;drop&#x27;,\n",
       "                                                  [&#x27;Time&#x27;, &#x27;Amount&#x27;])])),\n",
       "                (&#x27;mlp&#x27;,\n",
       "                 KerasClassifier(batch_size=32, callbacks=[&lt;keras.src.callbacks.early_stopping.EarlyStopping object at 0x15923adb0&gt;], epochs=100, model=&lt;function create_model at 0x154a476a0&gt;, model__dropout_rate=0.37840920206250117, model__learning_rate=0.0008773260590279343, model__neurons=83, validation_split=0.2))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-79\" type=\"checkbox\" ><label for=\"sk-estimator-id-79\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(force_int_remainder_cols=False,\n",
       "                                   remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;drop_cols&#x27;, &#x27;drop&#x27;,\n",
       "                                                  [&#x27;Time&#x27;, &#x27;Amount&#x27;])])),\n",
       "                (&#x27;mlp&#x27;,\n",
       "                 KerasClassifier(batch_size=32, callbacks=[&lt;keras.src.callbacks.early_stopping.EarlyStopping object at 0x15923adb0&gt;], epochs=100, model=&lt;function create_model at 0x154a476a0&gt;, model__dropout_rate=0.37840920206250117, model__learning_rate=0.0008773260590279343, model__neurons=83, validation_split=0.2))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-80\" type=\"checkbox\" ><label for=\"sk-estimator-id-80\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;preprocessor: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(force_int_remainder_cols=False, remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;drop_cols&#x27;, &#x27;drop&#x27;, [&#x27;Time&#x27;, &#x27;Amount&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-81\" type=\"checkbox\" ><label for=\"sk-estimator-id-81\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">drop_cols</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;Time&#x27;, &#x27;Amount&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-82\" type=\"checkbox\" ><label for=\"sk-estimator-id-82\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">drop</label><div class=\"sk-toggleable__content fitted\"><pre>drop</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-83\" type=\"checkbox\" ><label for=\"sk-estimator-id-83\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">remainder</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;V1&#x27;, &#x27;V2&#x27;, &#x27;V3&#x27;, &#x27;V4&#x27;, &#x27;V5&#x27;, &#x27;V6&#x27;, &#x27;V7&#x27;, &#x27;V8&#x27;, &#x27;V9&#x27;, &#x27;V10&#x27;, &#x27;V11&#x27;, &#x27;V12&#x27;, &#x27;V13&#x27;, &#x27;V14&#x27;, &#x27;V15&#x27;, &#x27;V16&#x27;, &#x27;V17&#x27;, &#x27;V18&#x27;, &#x27;V19&#x27;, &#x27;V20&#x27;, &#x27;V21&#x27;, &#x27;V22&#x27;, &#x27;V23&#x27;, &#x27;V24&#x27;, &#x27;V25&#x27;, &#x27;V26&#x27;, &#x27;V27&#x27;, &#x27;V28&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-84\" type=\"checkbox\" ><label for=\"sk-estimator-id-84\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">passthrough</label><div class=\"sk-toggleable__content fitted\"><pre>passthrough</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-85\" type=\"checkbox\" ><label for=\"sk-estimator-id-85\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">KerasClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;function create_model at 0x154a476a0&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=32\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=[&lt;keras.src.callbacks.early_stopping.EarlyStopping object at 0x15923adb0&gt;]\n",
       "\tvalidation_split=0.2\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=100\n",
       "\tclass_weight=None\n",
       "\tmodel__dropout_rate=0.37840920206250117\n",
       "\tmodel__learning_rate=0.0008773260590279343\n",
       "\tmodel__neurons=83\n",
       ")</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(force_int_remainder_cols=False,\n",
       "                                   remainder='passthrough',\n",
       "                                   transformers=[('drop_cols', 'drop',\n",
       "                                                  ['Time', 'Amount'])])),\n",
       "                ('mlp',\n",
       "                 KerasClassifier(batch_size=32, callbacks=[<keras.src.callbacks.early_stopping.EarlyStopping object at 0x15923adb0>], epochs=100, model=<function create_model at 0x154a476a0>, model__dropout_rate=0.37840920206250117, model__learning_rate=0.0008773260590279343, model__neurons=83, validation_split=0.2))])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define parameter grid\n",
    "param_distributions = {\n",
    "    'mlp__model__learning_rate': uniform(0.0005, 0.005),  # Smaller range\n",
    "    'mlp__model__neurons': randint(64, 128),  # No small networks\n",
    "    'mlp__model__dropout_rate': uniform(0.2, 0.4),  # Dropout is now reasonable\n",
    "    'mlp__epochs': [50, 100],  # Avoid unnecessary low values\n",
    "    'mlp__batch_size': [32, 64]  # Avoid extreme batch sizes\n",
    "}\n",
    "\n",
    "# Run Randomized Search\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=13)\n",
    "random_search_mlp = RandomizedSearchCV(mlp_pipe, param_distributions, n_iter=10, cv=skf, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit model\n",
    "random_search_mlp.fit(X_train, y_train)\n",
    "\n",
    "# Print best hyperparameters\n",
    "print(\"Best hyperparameters:\", random_search_mlp.best_params_)\n",
    "\n",
    "\n",
    "mlp_tuned = random_search_mlp.best_estimator_\n",
    "mlp_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2660/2660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp_tuned_preds = mlp_tuned.predict(X_test)\n",
    "cm_mlp_tuned = confusion_matrix(y_test, y_pred_mlp)\n",
    "\n",
    "mlp_tuned_results = {\n",
    "    'Model': 'Multi Layer Perceptron',\n",
    "    'Sampling': 'NONE',\n",
    "    'Recall':round(recall_score(y_test, mlp_tuned_preds),2),\n",
    "    'Precision': round(precision_score(y_test, mlp_tuned_preds),2),\n",
    "    'F1 Score': round(f1_score(y_test, mlp_tuned_preds),2),\n",
    "    'PR-AUC': round(average_precision_score(y_test, mlp_tuned_preds),2),\n",
    "    'ROC-AUC': round(roc_auc_score(y_test, mlp_tuned_preds),2),\n",
    "    'True Negative': cm_mlp[0,0],\n",
    "    'False Positive': cm_mlp[0,1],\n",
    "    'False Negative': cm_mlp[1,0],\n",
    "    'True Positive': cm_mlp[1,1]\n",
    "}\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, mlp_tuned_preds, display_labels=['Not Fraud', 'Fraud'], values_format='d', cmap='Purples');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model': 'Multi Layer Perceptron',\n",
       " 'Sampling': 'NONE',\n",
       " 'Recall': 0.76,\n",
       " 'Precision': 0.83,\n",
       " 'F1 Score': 0.79,\n",
       " 'PR-AUC': 0.63,\n",
       " 'ROC-AUC': 0.88,\n",
       " 'True Negative': 84963,\n",
       " 'False Positive': 13,\n",
       " 'False Negative': 35,\n",
       " 'True Positive': 107}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp_tuned_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Hyperparameter Tuning with BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint, loguniform\n",
    "\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids = {\n",
    "    'logreg_rus' : {\n",
    "        'rus__sampling_strategy': uniform(loc=0.2, scale=1.0),\n",
    "        'classifier__max_iter': randint(500, 5001),\n",
    "        'classifier__C': loguniform(0.01, 10.0)\n",
    "        },\n",
    "                               \n",
    "    'xgboost_smote' : {\n",
    "        'smote__sampling_strategy': uniform(loc=0.2, scale=0.8),\n",
    "        'smote__k_neighbors': randint(3, 8),\n",
    "        'classifier__n_estimators': randint(100, 501),\n",
    "        'classifier__max_depth': randint(3, 11),\n",
    "        'classifier__learning_rate': loguniform(0.01, 0.3),\n",
    "        'classifier__subsample': uniform(loc=0.6, scale=0.4)\n",
    "        },\n",
    "\n",
    "    'rf_smote_rus' : {\n",
    "        'smote__sampling_strategy': uniform(loc=0.2, scale=0.8),\n",
    "        'smote__k_neighbors': randint(3, 8),\n",
    "        'rus__sampling_strategy': uniform(loc=0.2, scale=0.8),\n",
    "        'classifier__n_estimators': randint(100, 501),\n",
    "        'classifier__max_depth': randint(3, 21),\n",
    "        'classifier__min_samples_split': randint(2, 21),\n",
    "        'classifier__min_samples_leaf': randint(1, 21)}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search_cv(algorithm, pipe_steps, param_grid, preprocessor='v1', scoring='Recall', n_iter=10, cv=5, n_jobs=-1):\n",
    "    \n",
    "    if preprocessor == 'v1':\n",
    "        preproc = ColumnTransformer(\n",
    "            transformers=[('drop_cols', 'drop', ['Time', 'Amount'])],\n",
    "            remainder='passthrough')\n",
    "    else:\n",
    "        preproc = preprocessor\n",
    "\n",
    "    steps = pipe_steps.copy()\n",
    "\n",
    "    if preproc:\n",
    "        steps.insert(0, ('preprocessor', preproc))\n",
    "\n",
    "    steps.append(('classifier', algorithm))\n",
    "\n",
    "    pipe = imbPipe(steps=steps)\n",
    "    rscv = RandomizedSearchCV(pipe,\n",
    "                              param_distributions=param_grid,\n",
    "                              n_iter=n_iter,\n",
    "                              cv=cv,\n",
    "                              scoring=scoring,\n",
    "                              random_state=13,\n",
    "                              n_jobs=n_jobs)\n",
    "    \n",
    "    rscv.fit(X_train, y_train)\n",
    "    best_params = rscv.best_params_\n",
    "    best_score = rscv.best_score_\n",
    "    best_model = rscv.best_estimator_\n",
    "\n",
    "    return best_model, best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "15 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 329, in fit\n",
      "    Xt, yt = self._fit(X, y, routed_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 265, in _fit\n",
      "    X, y, fitted_transformer = fit_resample_one_cached(\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 1057, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **params.get(\"fit_resample\", {}))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/base.py\", line 207, in fit_resample\n",
      "    self._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/base.py\", line 42, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'sampling_strategy' parameter of RandomUnderSampler must be a float in the range (0.0, 1.0], a str among {'all', 'auto', 'not minority', 'not majority', 'majority'}, an instance of 'collections.abc.Mapping' or a callable. Got 1.0594340147396812 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 329, in fit\n",
      "    Xt, yt = self._fit(X, y, routed_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 265, in _fit\n",
      "    X, y, fitted_transformer = fit_resample_one_cached(\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 1057, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **params.get(\"fit_resample\", {}))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/base.py\", line 207, in fit_resample\n",
      "    self._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/base.py\", line 42, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'sampling_strategy' parameter of RandomUnderSampler must be a float in the range (0.0, 1.0], a str among {'all', 'not minority', 'not majority', 'majority', 'auto'}, an instance of 'collections.abc.Mapping' or a callable. Got 1.0594340147396812 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 329, in fit\n",
      "    Xt, yt = self._fit(X, y, routed_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 265, in _fit\n",
      "    X, y, fitted_transformer = fit_resample_one_cached(\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 1057, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **params.get(\"fit_resample\", {}))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/base.py\", line 207, in fit_resample\n",
      "    self._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/base.py\", line 42, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'sampling_strategy' parameter of RandomUnderSampler must be a float in the range (0.0, 1.0], a str among {'auto', 'not majority', 'majority', 'not minority', 'all'}, an instance of 'collections.abc.Mapping' or a callable. Got 1.0594340147396812 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 329, in fit\n",
      "    Xt, yt = self._fit(X, y, routed_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 265, in _fit\n",
      "    X, y, fitted_transformer = fit_resample_one_cached(\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 1057, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **params.get(\"fit_resample\", {}))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/base.py\", line 207, in fit_resample\n",
      "    self._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/base.py\", line 42, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'sampling_strategy' parameter of RandomUnderSampler must be a float in the range (0.0, 1.0], a str among {'not minority', 'auto', 'majority', 'all', 'not majority'}, an instance of 'collections.abc.Mapping' or a callable. Got 1.0594340147396812 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 329, in fit\n",
      "    Xt, yt = self._fit(X, y, routed_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 265, in _fit\n",
      "    X, y, fitted_transformer = fit_resample_one_cached(\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 1057, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **params.get(\"fit_resample\", {}))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/base.py\", line 207, in fit_resample\n",
      "    self._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/base.py\", line 42, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'sampling_strategy' parameter of RandomUnderSampler must be a float in the range (0.0, 1.0], a str among {'all', 'not minority', 'not majority', 'majority', 'auto'}, an instance of 'collections.abc.Mapping' or a callable. Got 1.1726011139048933 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 329, in fit\n",
      "    Xt, yt = self._fit(X, y, routed_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 265, in _fit\n",
      "    X, y, fitted_transformer = fit_resample_one_cached(\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 1057, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **params.get(\"fit_resample\", {}))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/base.py\", line 207, in fit_resample\n",
      "    self._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/base.py\", line 42, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'sampling_strategy' parameter of RandomUnderSampler must be a float in the range (0.0, 1.0], a str among {'auto', 'not majority', 'majority', 'not minority', 'all'}, an instance of 'collections.abc.Mapping' or a callable. Got 1.1726011139048933 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 329, in fit\n",
      "    Xt, yt = self._fit(X, y, routed_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 265, in _fit\n",
      "    X, y, fitted_transformer = fit_resample_one_cached(\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 1057, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **params.get(\"fit_resample\", {}))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/base.py\", line 207, in fit_resample\n",
      "    self._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/base.py\", line 42, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'sampling_strategy' parameter of RandomUnderSampler must be a float in the range (0.0, 1.0], a str among {'not minority', 'auto', 'majority', 'all', 'not majority'}, an instance of 'collections.abc.Mapping' or a callable. Got 1.1726011139048933 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 329, in fit\n",
      "    Xt, yt = self._fit(X, y, routed_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 265, in _fit\n",
      "    X, y, fitted_transformer = fit_resample_one_cached(\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 1057, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **params.get(\"fit_resample\", {}))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/base.py\", line 207, in fit_resample\n",
      "    self._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/base.py\", line 42, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'sampling_strategy' parameter of RandomUnderSampler must be a float in the range (0.0, 1.0], a str among {'all', 'auto', 'not minority', 'not majority', 'majority'}, an instance of 'collections.abc.Mapping' or a callable. Got 1.1726011139048933 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 329, in fit\n",
      "    Xt, yt = self._fit(X, y, routed_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 265, in _fit\n",
      "    X, y, fitted_transformer = fit_resample_one_cached(\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 1057, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **params.get(\"fit_resample\", {}))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/base.py\", line 207, in fit_resample\n",
      "    self._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/base.py\", line 42, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'sampling_strategy' parameter of RandomUnderSampler must be a float in the range (0.0, 1.0], a str among {'auto', 'not majority', 'majority', 'not minority', 'all'}, an instance of 'collections.abc.Mapping' or a callable. Got 1.0570609425871988 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 329, in fit\n",
      "    Xt, yt = self._fit(X, y, routed_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 265, in _fit\n",
      "    X, y, fitted_transformer = fit_resample_one_cached(\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 1057, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **params.get(\"fit_resample\", {}))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/base.py\", line 207, in fit_resample\n",
      "    self._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/base.py\", line 42, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'sampling_strategy' parameter of RandomUnderSampler must be a float in the range (0.0, 1.0], a str among {'all', 'not minority', 'not majority', 'majority', 'auto'}, an instance of 'collections.abc.Mapping' or a callable. Got 1.0570609425871988 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 329, in fit\n",
      "    Xt, yt = self._fit(X, y, routed_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 265, in _fit\n",
      "    X, y, fitted_transformer = fit_resample_one_cached(\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 1057, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **params.get(\"fit_resample\", {}))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/base.py\", line 207, in fit_resample\n",
      "    self._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/base.py\", line 42, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'sampling_strategy' parameter of RandomUnderSampler must be a float in the range (0.0, 1.0], a str among {'not minority', 'auto', 'majority', 'all', 'not majority'}, an instance of 'collections.abc.Mapping' or a callable. Got 1.0570609425871988 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1102: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.4979997  0.50344477        nan 0.53349517\n",
      " 0.67747753 0.53956944 0.54682532 0.52793358]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lr_best_model, lr_best_params, lr_best_score = random_search_cv(algorithms['Logistic Regression'], pipe_steps=pipelines['RUS'], param_grid=grids['logreg_rus'], scoring='average_precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6774775322396709"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/lr_rus.joblib']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_randsearch = lr_best_model\n",
    "dump(lr_randsearch, '../models/lr_rus.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best_model, xgb_best_params, xgb_best_score = random_search_cv(algorithms['XGBoost'], pipe_steps=pipelines['SMOTE'], param_grid=grids['xgboost_smote'], scoring='average_precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.854305911775942\n"
     ]
    }
   ],
   "source": [
    "xgb_best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/xgb_smote.joblib']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_randsearch = xgb_best_model\n",
    "dump(lr_randsearch, '../models/xgb_smote.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "20 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 329, in fit\n",
      "    Xt, yt = self._fit(X, y, routed_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 265, in _fit\n",
      "    X, y, fitted_transformer = fit_resample_one_cached(\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/pipeline.py\", line 1057, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **params.get(\"fit_resample\", {}))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/base.py\", line 208, in fit_resample\n",
      "    return super().fit_resample(X, y)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/base.py\", line 108, in fit_resample\n",
      "    self.sampling_strategy_ = check_sampling_strategy(\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/utils/_validation.py\", line 571, in check_sampling_strategy\n",
      "    _sampling_strategy_float(sampling_strategy, y, sampling_type).items()\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/imblearn/utils/_validation.py\", line 430, in _sampling_strategy_float\n",
      "    raise ValueError(\n",
      "ValueError: The specified ratio required to generate new sample in the majority class while trying to remove samples. Please increase the ratio.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1102: UserWarning: One or more of the test scores are non-finite: [       nan 0.74867642        nan 0.8227225  0.8274659  0.81310854\n",
      " 0.84316731        nan 0.70906174        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rf_best_model, rf_best_params, rf_best_score = random_search_cv(algorithms['Random Forest'], pipe_steps=pipelines['SMOTE+RUS'], param_grid=grids['rf_smote_rus'], scoring='average_precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8431673092855443"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/rf_smote_rus.joblib']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_randsearch = rf_best_model\n",
    "dump(lr_randsearch, '../models/rf_smote_rus.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = {\n",
    "    'Logistic Regression: RUS': lr_best_model,\n",
    "    'Random Forest: SMOTE + RUS': rf_best_model,\n",
    "    'XGBoost: SMOTE': xgb_best_model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1950x500 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True Negative</th>\n",
       "      <th>False Positive</th>\n",
       "      <th>False Negative</th>\n",
       "      <th>True Positive</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>PR-AUC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression: RUS</th>\n",
       "      <td>84417</td>\n",
       "      <td>559</td>\n",
       "      <td>20</td>\n",
       "      <td>122</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest: SMOTE + RUS</th>\n",
       "      <td>84948</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>114</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost: SMOTE</th>\n",
       "      <td>84950</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>111</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            True Negative  False Positive  False Negative  \\\n",
       "Model                                                                       \n",
       "Logistic Regression: RUS            84417             559              20   \n",
       "Random Forest: SMOTE + RUS          84948              28              28   \n",
       "XGBoost: SMOTE                      84950              26              31   \n",
       "\n",
       "                            True Positive  Recall  Precision  F1 Score  PR-AUC  \n",
       "Model                                                                           \n",
       "Logistic Regression: RUS              122    0.86       0.18       0.3    0.15  \n",
       "Random Forest: SMOTE + RUS            114    0.80       0.80       0.8    0.64  \n",
       "XGBoost: SMOTE                        111    0.78       0.81       0.8    0.63  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_evaluation(X_train, y_train, X_test, y_test, algorithms=best_models, pre_fitted=True, pipelines=None, preprocessor='v1', calculate_scores=True, normalize=None, cmap='Purples', cols=3)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
